{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3mTIrD710cayJLO+ZJCzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kthhtk/AIFFEL_Quest_cr/blob/master/Python/KerasTuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-b7Kf2fdPhk",
        "outputId": "916a8715-77e5-4692-ea66-825f49d17326"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.12.14)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3oWVrUfjdIoU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras_tuner import RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYBvJk1jdLZM",
        "outputId": "363b30fd-258a-4d03-d95a-296044728ce0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "\n",
        "### 모델 구성\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G__x8pnndb8E",
        "outputId": "1720840e-7c74-4c4b-95af-2938294a4100"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=20,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBShHH37iClq",
        "outputId": "164e8caf-8d98-491e-cd4b-2f7bc5b10274"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.4257 - loss: 1.5908 - val_accuracy: 0.5381 - val_loss: 1.3386\n",
            "Epoch 2/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6215 - loss: 1.0679 - val_accuracy: 0.5479 - val_loss: 1.3179\n",
            "Epoch 3/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.6788 - loss: 0.9066 - val_accuracy: 0.5777 - val_loss: 1.2014\n",
            "Epoch 4/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7156 - loss: 0.8064 - val_accuracy: 0.6656 - val_loss: 0.9554\n",
            "Epoch 5/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.7239 - val_accuracy: 0.6105 - val_loss: 1.2654\n",
            "Epoch 6/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7683 - loss: 0.6650 - val_accuracy: 0.6256 - val_loss: 1.1371\n",
            "Epoch 7/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.5903 - val_accuracy: 0.6189 - val_loss: 1.3243\n",
            "Epoch 8/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8078 - loss: 0.5434 - val_accuracy: 0.6822 - val_loss: 0.9592\n",
            "Epoch 9/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.4947 - val_accuracy: 0.7155 - val_loss: 0.8942\n",
            "Epoch 10/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8408 - loss: 0.4498 - val_accuracy: 0.6790 - val_loss: 1.0057\n",
            "Epoch 11/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.4113 - val_accuracy: 0.6559 - val_loss: 1.1138\n",
            "Epoch 12/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3793 - val_accuracy: 0.7083 - val_loss: 0.9580\n",
            "Epoch 13/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8755 - loss: 0.3470 - val_accuracy: 0.6821 - val_loss: 1.1106\n",
            "Epoch 14/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8823 - loss: 0.3229 - val_accuracy: 0.7026 - val_loss: 1.1116\n",
            "Epoch 15/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2991 - val_accuracy: 0.7034 - val_loss: 1.0894\n",
            "Epoch 16/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8960 - loss: 0.2876 - val_accuracy: 0.6835 - val_loss: 1.2576\n",
            "Epoch 17/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2571 - val_accuracy: 0.6595 - val_loss: 1.4780\n",
            "Epoch 18/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2461 - val_accuracy: 0.6970 - val_loss: 1.2714\n",
            "Epoch 19/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9171 - loss: 0.2315 - val_accuracy: 0.7040 - val_loss: 1.2355\n",
            "Epoch 20/20\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2246 - val_accuracy: 0.7109 - val_loss: 1.1810\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 1.2028\n",
            "Test accuracy: 0.6995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIbHh_VViW45",
        "outputId": "4aaf44f2-c3e9-415d-827e-871ae55c4275"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7012 - loss: 1.2028\n",
            "Test accuracy: 0.6995\n",
            "Test loss: 1.2110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 드롭아웃 비율 수정\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.4))  # 1. 드롭아웃 비율 수정: 0.2 -> 0.4\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# 2. 학습률 수정\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),  # 0.001 -> 0.0005 으로 감소\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# 3. 배치 사이즈 수정\n",
        "batch_size = 32  # 기본값 64에서 감소\n",
        "# 4. 에포크 수 증가\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=40,  # 기존 20에서 증가\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qz8BYkAzi8fK",
        "outputId": "9d246b76-0f0a-4453-ff07-2112355e2b1a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.3962 - loss: 1.6680 - val_accuracy: 0.5680 - val_loss: 1.2226\n",
            "Epoch 2/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5929 - loss: 1.1528 - val_accuracy: 0.6413 - val_loss: 1.0208\n",
            "Epoch 3/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6544 - loss: 0.9920 - val_accuracy: 0.6709 - val_loss: 0.9290\n",
            "Epoch 4/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6858 - loss: 0.8932 - val_accuracy: 0.6305 - val_loss: 1.0962\n",
            "Epoch 5/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.8135 - val_accuracy: 0.6519 - val_loss: 1.0142\n",
            "Epoch 6/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7395 - loss: 0.7440 - val_accuracy: 0.6882 - val_loss: 0.8859\n",
            "Epoch 7/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.7104 - val_accuracy: 0.6834 - val_loss: 0.9261\n",
            "Epoch 8/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7745 - loss: 0.6540 - val_accuracy: 0.7165 - val_loss: 0.8358\n",
            "Epoch 9/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7838 - loss: 0.6139 - val_accuracy: 0.7001 - val_loss: 0.8819\n",
            "Epoch 10/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7959 - loss: 0.5817 - val_accuracy: 0.7013 - val_loss: 0.8852\n",
            "Epoch 11/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.5465 - val_accuracy: 0.7067 - val_loss: 0.9136\n",
            "Epoch 12/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8180 - loss: 0.5130 - val_accuracy: 0.7216 - val_loss: 0.8338\n",
            "Epoch 13/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8288 - loss: 0.4876 - val_accuracy: 0.6995 - val_loss: 0.9635\n",
            "Epoch 14/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8375 - loss: 0.4551 - val_accuracy: 0.7279 - val_loss: 0.8621\n",
            "Epoch 15/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8397 - loss: 0.4415 - val_accuracy: 0.7173 - val_loss: 0.8560\n",
            "Epoch 16/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.4161 - val_accuracy: 0.7228 - val_loss: 0.8753\n",
            "Epoch 17/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8546 - loss: 0.4062 - val_accuracy: 0.7166 - val_loss: 0.9067\n",
            "Epoch 18/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.3792 - val_accuracy: 0.7381 - val_loss: 0.8842\n",
            "Epoch 19/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3719 - val_accuracy: 0.7184 - val_loss: 0.9477\n",
            "Epoch 20/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8762 - loss: 0.3494 - val_accuracy: 0.7277 - val_loss: 0.9332\n",
            "Epoch 21/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8834 - loss: 0.3324 - val_accuracy: 0.6750 - val_loss: 1.2368\n",
            "Epoch 22/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8830 - loss: 0.3299 - val_accuracy: 0.6987 - val_loss: 1.0197\n",
            "Epoch 23/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3177 - val_accuracy: 0.7278 - val_loss: 0.9073\n",
            "Epoch 24/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.3133 - val_accuracy: 0.7424 - val_loss: 0.9010\n",
            "Epoch 25/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2984 - val_accuracy: 0.7403 - val_loss: 0.9283\n",
            "Epoch 26/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.2962 - val_accuracy: 0.7361 - val_loss: 0.9334\n",
            "Epoch 27/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9012 - loss: 0.2788 - val_accuracy: 0.7279 - val_loss: 0.9957\n",
            "Epoch 28/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9005 - loss: 0.2781 - val_accuracy: 0.7386 - val_loss: 0.9303\n",
            "Epoch 29/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9066 - loss: 0.2630 - val_accuracy: 0.7284 - val_loss: 0.9837\n",
            "Epoch 30/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2663 - val_accuracy: 0.6979 - val_loss: 1.1380\n",
            "Epoch 31/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9060 - loss: 0.2630 - val_accuracy: 0.7338 - val_loss: 0.9667\n",
            "Epoch 32/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.2533 - val_accuracy: 0.7267 - val_loss: 1.0196\n",
            "Epoch 33/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2388 - val_accuracy: 0.7299 - val_loss: 1.0046\n",
            "Epoch 34/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2411 - val_accuracy: 0.7100 - val_loss: 1.1637\n",
            "Epoch 35/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2350 - val_accuracy: 0.7253 - val_loss: 1.0597\n",
            "Epoch 36/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2301 - val_accuracy: 0.7421 - val_loss: 0.9826\n",
            "Epoch 37/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2345 - val_accuracy: 0.7297 - val_loss: 1.0317\n",
            "Epoch 38/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2239 - val_accuracy: 0.7356 - val_loss: 0.9708\n",
            "Epoch 39/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9219 - loss: 0.2180 - val_accuracy: 0.7194 - val_loss: 1.1542\n",
            "Epoch 40/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2239 - val_accuracy: 0.7351 - val_loss: 1.0045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM0es_T_mnKu",
        "outputId": "e605edaa-a113-4e81-b2a0-9e1e15733f2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 1.0052\n",
            "Test accuracy: 0.7289\n",
            "Test loss: 1.0132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "val_accuracy를 높이기 위해...\n"
      ],
      "metadata": {
        "id": "EiM1eMB4n5hw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 증강은 모델의 첫 부분에 추가\n",
        "model = keras.Sequential([\n",
        "    # 데이터 증강 레이어를 가장 먼저 추가\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "\n",
        "    # 기존 모델 구조\n",
        "    layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, kernel_size=3, activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.5),  # 드롭아웃 비율 0.5로 증가\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 2. 모델 컴파일\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 3. Early Stopping 콜백 정의\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True  # 가장 좋은 가중치 복원\n",
        ")\n",
        "\n",
        "# 4. 모델 학습 시 콜백 적용\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=32,\n",
        "    epochs=50, # 10 증가\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping]  # 콜백 리스트에 추가\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3oWsmT3nkK3",
        "outputId": "b43889ed-982a-46cc-a20d-279633d7c7ea"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.3514 - loss: 1.7980 - val_accuracy: 0.4901 - val_loss: 1.4287\n",
            "Epoch 2/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 7ms/step - accuracy: 0.4990 - loss: 1.3872 - val_accuracy: 0.5033 - val_loss: 1.4816\n",
            "Epoch 3/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5415 - loss: 1.2889 - val_accuracy: 0.5498 - val_loss: 1.3004\n",
            "Epoch 4/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.5654 - loss: 1.2279 - val_accuracy: 0.6183 - val_loss: 1.0928\n",
            "Epoch 5/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.5849 - loss: 1.1789 - val_accuracy: 0.6168 - val_loss: 1.1184\n",
            "Epoch 6/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5978 - loss: 1.1375 - val_accuracy: 0.6206 - val_loss: 1.1086\n",
            "Epoch 7/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.6089 - loss: 1.1063 - val_accuracy: 0.6382 - val_loss: 1.0468\n",
            "Epoch 8/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6134 - loss: 1.0948 - val_accuracy: 0.6536 - val_loss: 1.0312\n",
            "Epoch 9/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6264 - loss: 1.0545 - val_accuracy: 0.6680 - val_loss: 0.9716\n",
            "Epoch 10/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6383 - loss: 1.0302 - val_accuracy: 0.6581 - val_loss: 1.0039\n",
            "Epoch 11/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.6448 - loss: 1.0181 - val_accuracy: 0.6713 - val_loss: 0.9571\n",
            "Epoch 12/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.6470 - loss: 1.0062 - val_accuracy: 0.6710 - val_loss: 0.9690\n",
            "Epoch 13/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6517 - loss: 0.9929 - val_accuracy: 0.6592 - val_loss: 0.9691\n",
            "Epoch 14/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.6621 - loss: 0.9655 - val_accuracy: 0.6844 - val_loss: 0.9470\n",
            "Epoch 15/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.6583 - loss: 0.9707 - val_accuracy: 0.6679 - val_loss: 0.9558\n",
            "Epoch 16/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6679 - loss: 0.9516 - val_accuracy: 0.6840 - val_loss: 0.9556\n",
            "Epoch 17/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.6755 - loss: 0.9377 - val_accuracy: 0.6817 - val_loss: 0.9535\n",
            "Epoch 18/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.6761 - loss: 0.9303 - val_accuracy: 0.6263 - val_loss: 1.1673\n",
            "Epoch 19/50\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.6830 - loss: 0.9098 - val_accuracy: 0.6186 - val_loss: 1.1352\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "val_acc 0.6으로 떨어짐"
      ],
      "metadata": {
        "id": "wE8YnlripQHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 모델 레이어\n",
        "model = keras.Sequential()\n",
        "model.add(layers.Conv2D(32, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Dropout(0.3))  # 과적합 개선 1: 드롭아웃 비율 0.4->0.3으로 조정\n",
        "model.add(layers.BatchNormalization())  # 과적합 개선 2: BatchNormalization 추가\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.2))  # val_acc 개선 1: Dense층 사이에 드롭아웃 추가\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# 2. 학습률\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003),  # val_acc 개선 2: learning rate 더 감소\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "# 3. 배치 사이즈\n",
        "batch_size = 32\n",
        "# 4. 에포크 수\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=40,\n",
        "    validation_split=0.2\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKobnFsywbbh",
        "outputId": "2de5db6a-6054-4c6c-9b1f-737f5cfa0332"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.3583 - loss: 1.9130 - val_accuracy: 0.5799 - val_loss: 1.2035\n",
            "Epoch 2/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5566 - loss: 1.2629 - val_accuracy: 0.6078 - val_loss: 1.0975\n",
            "Epoch 3/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6293 - loss: 1.0616 - val_accuracy: 0.6491 - val_loss: 1.0035\n",
            "Epoch 4/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6676 - loss: 0.9550 - val_accuracy: 0.6092 - val_loss: 1.1021\n",
            "Epoch 5/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6959 - loss: 0.8560 - val_accuracy: 0.6906 - val_loss: 0.8867\n",
            "Epoch 6/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7204 - loss: 0.7890 - val_accuracy: 0.6796 - val_loss: 0.9117\n",
            "Epoch 7/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.7411 - val_accuracy: 0.7090 - val_loss: 0.8289\n",
            "Epoch 8/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7587 - loss: 0.6899 - val_accuracy: 0.6950 - val_loss: 0.8794\n",
            "Epoch 9/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7732 - loss: 0.6442 - val_accuracy: 0.7178 - val_loss: 0.8107\n",
            "Epoch 10/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7839 - loss: 0.6145 - val_accuracy: 0.7273 - val_loss: 0.8012\n",
            "Epoch 11/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5825 - val_accuracy: 0.7269 - val_loss: 0.7968\n",
            "Epoch 12/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8033 - loss: 0.5628 - val_accuracy: 0.7215 - val_loss: 0.8148\n",
            "Epoch 13/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8151 - loss: 0.5210 - val_accuracy: 0.7357 - val_loss: 0.8032\n",
            "Epoch 14/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8232 - loss: 0.4985 - val_accuracy: 0.7118 - val_loss: 0.8486\n",
            "Epoch 15/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.4749 - val_accuracy: 0.7404 - val_loss: 0.7828\n",
            "Epoch 16/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8332 - loss: 0.4700 - val_accuracy: 0.6972 - val_loss: 0.9471\n",
            "Epoch 17/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8459 - loss: 0.4397 - val_accuracy: 0.7285 - val_loss: 0.8265\n",
            "Epoch 18/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8494 - loss: 0.4237 - val_accuracy: 0.7252 - val_loss: 0.8472\n",
            "Epoch 19/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8516 - loss: 0.4117 - val_accuracy: 0.7220 - val_loss: 0.8589\n",
            "Epoch 20/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8541 - loss: 0.4069 - val_accuracy: 0.7380 - val_loss: 0.7950\n",
            "Epoch 21/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3932 - val_accuracy: 0.7453 - val_loss: 0.7943\n",
            "Epoch 22/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3829 - val_accuracy: 0.7327 - val_loss: 0.8442\n",
            "Epoch 23/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8664 - loss: 0.3718 - val_accuracy: 0.7309 - val_loss: 0.8495\n",
            "Epoch 24/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3638 - val_accuracy: 0.7340 - val_loss: 0.8424\n",
            "Epoch 25/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8753 - loss: 0.3544 - val_accuracy: 0.7250 - val_loss: 0.8680\n",
            "Epoch 26/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8748 - loss: 0.3429 - val_accuracy: 0.7377 - val_loss: 0.8140\n",
            "Epoch 27/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8814 - loss: 0.3331 - val_accuracy: 0.7265 - val_loss: 0.8596\n",
            "Epoch 28/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8767 - loss: 0.3409 - val_accuracy: 0.7343 - val_loss: 0.8610\n",
            "Epoch 29/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8846 - loss: 0.3274 - val_accuracy: 0.7309 - val_loss: 0.8621\n",
            "Epoch 30/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3277 - val_accuracy: 0.7394 - val_loss: 0.8722\n",
            "Epoch 31/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.3161 - val_accuracy: 0.7382 - val_loss: 0.8532\n",
            "Epoch 32/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.3126 - val_accuracy: 0.7403 - val_loss: 0.8327\n",
            "Epoch 33/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3072 - val_accuracy: 0.7281 - val_loss: 0.9454\n",
            "Epoch 34/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8928 - loss: 0.3026 - val_accuracy: 0.7383 - val_loss: 0.8596\n",
            "Epoch 35/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.3007 - val_accuracy: 0.7332 - val_loss: 0.8834\n",
            "Epoch 36/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8985 - loss: 0.2904 - val_accuracy: 0.7288 - val_loss: 0.8911\n",
            "Epoch 37/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8995 - loss: 0.2817 - val_accuracy: 0.7407 - val_loss: 0.9233\n",
            "Epoch 38/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2958 - val_accuracy: 0.7325 - val_loss: 0.9052\n",
            "Epoch 39/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8990 - loss: 0.2833 - val_accuracy: 0.7327 - val_loss: 0.9074\n",
            "Epoch 40/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8998 - loss: 0.2850 - val_accuracy: 0.7300 - val_loss: 0.8850\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 평가\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "print(f\"Test loss: {test_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1xeWMg0yS9T",
        "outputId": "e4c3b422-1f3d-4202-ce79-6b55dd8d68f7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7319 - loss: 0.8818\n",
            "Test accuracy: 0.7329\n",
            "Test loss: 0.8885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이것저것 추가해봤더니, 학습만 오래걸리고 성과가 더딤"
      ],
      "metadata": {
        "id": "IIFEdXDPyg6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    # 데이터 증강 레이어 - 더 다양한 augmentation 추가\n",
        "    layers.RandomFlip(\"horizontal_and_vertical\"),  # 수직 뒤집기 추가\n",
        "    layers.RandomRotation(0.2),  # 회전각도 증가\n",
        "    layers.RandomZoom(0.1),  # 확대/축소 추가\n",
        "    layers.RandomBrightness(0.2),  # 밝기 변화 추가\n",
        "\n",
        "    # 모델 구조 - 레이어 깊이와 정규화 강화\n",
        "    layers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32, kernel_size=3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# 컴파일 - learning rate 조정 및 optimizer 변경\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),  # learning rate 감소\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early Stopping - patience 증가 및 모니터링 지표 변경\n",
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',  # accuracy 기준으로 변경\n",
        "    patience=10,  # patience 증가\n",
        "    restore_best_weights=True,\n",
        "    mode='max'  # accuracy 모니터링을 위해 mode 변경\n",
        ")\n",
        "\n",
        "# Learning Rate 감소 콜백 추가\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,  # batch size 증가\n",
        "    epochs=100,  # epoch 수 증가\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping, reduce_lr]  # 콜백 추가\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J9gBjeaLpSTp",
        "outputId": "7eb7acca-e767-4974-8f3e-548988438a7e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception ignored in: <function _xla_gc_callback at 0x7f4641bd9900>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 20ms/step - accuracy: 0.1020 - loss: 3.2297 - val_accuracy: 0.1097 - val_loss: 2.3075 - learning_rate: 1.0000e-04\n",
            "Epoch 2/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.0964 - loss: 2.8860 - val_accuracy: 0.0890 - val_loss: 2.3077 - learning_rate: 1.0000e-04\n",
            "Epoch 3/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.1006 - loss: 2.7668 - val_accuracy: 0.1104 - val_loss: 2.2995 - learning_rate: 1.0000e-04\n",
            "Epoch 4/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.1041 - loss: 2.6808 - val_accuracy: 0.1051 - val_loss: 2.2996 - learning_rate: 1.0000e-04\n",
            "Epoch 5/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.1242 - loss: 2.5677 - val_accuracy: 0.1842 - val_loss: 2.2028 - learning_rate: 1.0000e-04\n",
            "Epoch 6/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1334 - loss: 2.5106 - val_accuracy: 0.2100 - val_loss: 2.2410 - learning_rate: 1.0000e-04\n",
            "Epoch 7/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.1411 - loss: 2.4404 - val_accuracy: 0.2170 - val_loss: 2.1399 - learning_rate: 1.0000e-04\n",
            "Epoch 8/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1502 - loss: 2.3789 - val_accuracy: 0.2167 - val_loss: 2.1181 - learning_rate: 1.0000e-04\n",
            "Epoch 9/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1600 - loss: 2.3359 - val_accuracy: 0.2380 - val_loss: 2.0683 - learning_rate: 1.0000e-04\n",
            "Epoch 10/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.1622 - loss: 2.2994 - val_accuracy: 0.2564 - val_loss: 2.0588 - learning_rate: 1.0000e-04\n",
            "Epoch 11/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1761 - loss: 2.2550 - val_accuracy: 0.2312 - val_loss: 2.0577 - learning_rate: 1.0000e-04\n",
            "Epoch 12/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1767 - loss: 2.2279 - val_accuracy: 0.1983 - val_loss: 2.2370 - learning_rate: 1.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.1809 - loss: 2.2168 - val_accuracy: 0.2864 - val_loss: 1.9538 - learning_rate: 1.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.1799 - loss: 2.1889 - val_accuracy: 0.2659 - val_loss: 2.0144 - learning_rate: 1.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1823 - loss: 2.1735 - val_accuracy: 0.2743 - val_loss: 1.9706 - learning_rate: 1.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1877 - loss: 2.1526 - val_accuracy: 0.3180 - val_loss: 1.8912 - learning_rate: 1.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.1978 - loss: 2.1355 - val_accuracy: 0.1877 - val_loss: 2.3131 - learning_rate: 1.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.1984 - loss: 2.1224 - val_accuracy: 0.2827 - val_loss: 1.9555 - learning_rate: 1.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2017 - loss: 2.1052 - val_accuracy: 0.2220 - val_loss: 2.3084 - learning_rate: 1.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2033 - loss: 2.1047 - val_accuracy: 0.3072 - val_loss: 1.9063 - learning_rate: 1.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2088 - loss: 2.0994 - val_accuracy: 0.3433 - val_loss: 1.8500 - learning_rate: 1.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.2133 - loss: 2.0775 - val_accuracy: 0.3276 - val_loss: 1.8577 - learning_rate: 1.0000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2112 - loss: 2.0777 - val_accuracy: 0.3055 - val_loss: 1.9072 - learning_rate: 1.0000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.2188 - loss: 2.0666 - val_accuracy: 0.3276 - val_loss: 1.8627 - learning_rate: 1.0000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2196 - loss: 2.0657 - val_accuracy: 0.3384 - val_loss: 1.8281 - learning_rate: 1.0000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2216 - loss: 2.0581 - val_accuracy: 0.3003 - val_loss: 1.8606 - learning_rate: 1.0000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.2228 - loss: 2.0617 - val_accuracy: 0.3185 - val_loss: 1.8438 - learning_rate: 1.0000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2245 - loss: 2.0485 - val_accuracy: 0.3720 - val_loss: 1.7686 - learning_rate: 1.0000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2316 - loss: 2.0341 - val_accuracy: 0.3480 - val_loss: 1.7899 - learning_rate: 1.0000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2245 - loss: 2.0402 - val_accuracy: 0.3500 - val_loss: 1.7846 - learning_rate: 1.0000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.2328 - loss: 2.0331 - val_accuracy: 0.3747 - val_loss: 1.7297 - learning_rate: 1.0000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.2277 - loss: 2.0266 - val_accuracy: 0.3604 - val_loss: 1.7688 - learning_rate: 1.0000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.2346 - loss: 2.0210 - val_accuracy: 0.3566 - val_loss: 1.7536 - learning_rate: 1.0000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2362 - loss: 2.0167 - val_accuracy: 0.3750 - val_loss: 1.7208 - learning_rate: 1.0000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2451 - loss: 2.0088 - val_accuracy: 0.3682 - val_loss: 1.7308 - learning_rate: 1.0000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.2448 - loss: 2.0083 - val_accuracy: 0.3629 - val_loss: 1.7342 - learning_rate: 1.0000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2453 - loss: 2.0014 - val_accuracy: 0.3801 - val_loss: 1.7251 - learning_rate: 1.0000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 19ms/step - accuracy: 0.2457 - loss: 1.9980 - val_accuracy: 0.3297 - val_loss: 1.8197 - learning_rate: 1.0000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2522 - loss: 1.9875 - val_accuracy: 0.4017 - val_loss: 1.6821 - learning_rate: 1.0000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - accuracy: 0.2493 - loss: 1.9891 - val_accuracy: 0.4093 - val_loss: 1.6586 - learning_rate: 1.0000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2529 - loss: 1.9828 - val_accuracy: 0.4083 - val_loss: 1.6616 - learning_rate: 1.0000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.2491 - loss: 1.9895 - val_accuracy: 0.3541 - val_loss: 1.7909 - learning_rate: 1.0000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - accuracy: 0.2557 - loss: 1.9855 - val_accuracy: 0.3767 - val_loss: 1.7205 - learning_rate: 1.0000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m302/625\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.2485 - loss: 1.9866"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-44233fb30f68>\u001b[0m in \u001b[0;36m<cell line: 53>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    # Conv2D 필터 수를 튜닝\n",
        "    filters = hp.Int('conv_1_units', min_value=16, max_value=64, step=16)\n",
        "    model.add(layers.Conv2D(filters, kernel_size=3, activation='relu', input_shape=(32, 32, 3)))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "\n",
        "    # 두 번째 Conv2D 레이어 필터 수 튜닝\n",
        "    filters_2 = hp.Int('conv_2_units', min_value=32, max_value=128, step=32)\n",
        "    model.add(layers.Conv2D(filters_2, kernel_size=3, activation='relu'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    # 드롭아웃 비율 튜닝\n",
        "    dropout_rate = hp.Float('dropout_1', min_value=0.1, max_value=0.5, step=0.1)\n",
        "    model.add(layers.Dropout(dropout_rate))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    # Dense 레이어 유닛 수 튜닝\n",
        "    units = hp.Int('dense_units', min_value=64, max_value=256, step=64)\n",
        "    model.add(layers.Dense(units, activation='relu'))\n",
        "    model.add(layers.Dropout(0.2))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    # 학습률 튜닝\n",
        "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "# RandomSearch 객체 생성\n",
        "tuner = kt.RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=5,  # 시도할 횟수\n",
        "    directory='my_dir',\n",
        "    project_name='cifar10_tuning'\n",
        ")\n",
        "\n",
        "# 탐색 시작\n",
        "tuner.search(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "# 최적의 하이퍼파라미터 확인\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# 최적의 모델 생성\n",
        "best_model = build_model(best_hps)\n",
        "\n",
        "# 최적의 모델 학습\n",
        "history = best_model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=40,\n",
        "    validation_split=0.2,\n",
        "    batch_size=32\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPiHemod1UAX",
        "outputId": "119716a1-0a9a-4d8b-9d4c-00a4f14f95e3"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 02m 28s]\n",
            "val_accuracy: 0.7142999768257141\n",
            "\n",
            "Best val_accuracy So Far: 0.738099992275238\n",
            "Total elapsed time: 00h 10m 10s\n",
            "Epoch 1/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.3039 - loss: 2.0920 - val_accuracy: 0.5303 - val_loss: 1.3301\n",
            "Epoch 2/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4847 - loss: 1.4793 - val_accuracy: 0.5735 - val_loss: 1.2117\n",
            "Epoch 3/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.5463 - loss: 1.2878 - val_accuracy: 0.6149 - val_loss: 1.1075\n",
            "Epoch 4/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5897 - loss: 1.1670 - val_accuracy: 0.6374 - val_loss: 1.0326\n",
            "Epoch 5/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6211 - loss: 1.0757 - val_accuracy: 0.6609 - val_loss: 0.9764\n",
            "Epoch 6/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6478 - loss: 1.0033 - val_accuracy: 0.6810 - val_loss: 0.9329\n",
            "Epoch 7/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.6629 - loss: 0.9533 - val_accuracy: 0.6756 - val_loss: 0.9298\n",
            "Epoch 8/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.6832 - loss: 0.9008 - val_accuracy: 0.6890 - val_loss: 0.8985\n",
            "Epoch 9/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7010 - loss: 0.8559 - val_accuracy: 0.6939 - val_loss: 0.8862\n",
            "Epoch 10/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7139 - loss: 0.8174 - val_accuracy: 0.7019 - val_loss: 0.8612\n",
            "Epoch 11/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7247 - loss: 0.7852 - val_accuracy: 0.6867 - val_loss: 0.8947\n",
            "Epoch 12/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.7442 - val_accuracy: 0.7138 - val_loss: 0.8411\n",
            "Epoch 13/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7452 - loss: 0.7183 - val_accuracy: 0.7255 - val_loss: 0.8054\n",
            "Epoch 14/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7593 - loss: 0.6891 - val_accuracy: 0.7063 - val_loss: 0.8579\n",
            "Epoch 15/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7679 - loss: 0.6671 - val_accuracy: 0.7230 - val_loss: 0.8063\n",
            "Epoch 16/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7768 - loss: 0.6321 - val_accuracy: 0.6864 - val_loss: 0.9216\n",
            "Epoch 17/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.6098 - val_accuracy: 0.7267 - val_loss: 0.7924\n",
            "Epoch 18/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7884 - loss: 0.5954 - val_accuracy: 0.7395 - val_loss: 0.7636\n",
            "Epoch 19/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7999 - loss: 0.5697 - val_accuracy: 0.7263 - val_loss: 0.8097\n",
            "Epoch 20/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8086 - loss: 0.5516 - val_accuracy: 0.7454 - val_loss: 0.7477\n",
            "Epoch 21/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8145 - loss: 0.5316 - val_accuracy: 0.7389 - val_loss: 0.7726\n",
            "Epoch 22/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8165 - loss: 0.5154 - val_accuracy: 0.7551 - val_loss: 0.7343\n",
            "Epoch 23/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8282 - loss: 0.4936 - val_accuracy: 0.7485 - val_loss: 0.7451\n",
            "Epoch 24/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.4787 - val_accuracy: 0.7491 - val_loss: 0.7511\n",
            "Epoch 25/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8341 - loss: 0.4713 - val_accuracy: 0.7504 - val_loss: 0.7433\n",
            "Epoch 26/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8422 - loss: 0.4487 - val_accuracy: 0.7499 - val_loss: 0.7583\n",
            "Epoch 27/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8480 - loss: 0.4403 - val_accuracy: 0.7564 - val_loss: 0.7312\n",
            "Epoch 28/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.4235 - val_accuracy: 0.7489 - val_loss: 0.7550\n",
            "Epoch 29/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8575 - loss: 0.4131 - val_accuracy: 0.7551 - val_loss: 0.7418\n",
            "Epoch 30/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.4017 - val_accuracy: 0.7489 - val_loss: 0.7668\n",
            "Epoch 31/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3913 - val_accuracy: 0.7450 - val_loss: 0.7732\n",
            "Epoch 32/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.3863 - val_accuracy: 0.7553 - val_loss: 0.7501\n",
            "Epoch 33/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8710 - loss: 0.3715 - val_accuracy: 0.7557 - val_loss: 0.7386\n",
            "Epoch 34/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8792 - loss: 0.3507 - val_accuracy: 0.7357 - val_loss: 0.8084\n",
            "Epoch 35/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.3390 - val_accuracy: 0.7518 - val_loss: 0.7605\n",
            "Epoch 36/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.3352 - val_accuracy: 0.7403 - val_loss: 0.8017\n",
            "Epoch 37/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8819 - loss: 0.3340 - val_accuracy: 0.7523 - val_loss: 0.7697\n",
            "Epoch 38/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.3109 - val_accuracy: 0.7511 - val_loss: 0.7582\n",
            "Epoch 39/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8943 - loss: 0.3052 - val_accuracy: 0.7450 - val_loss: 0.7885\n",
            "Epoch 40/40\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.3001 - val_accuracy: 0.7504 - val_loss: 0.7996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 학습 히스토리에서 정확도와 손실 값을 가져옴\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(val_acc) + 1)\n",
        "\n",
        "# 그래프 그리기\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# validation accuracy 그래프\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# validation loss 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 최종 값 출력\n",
        "print(f'Final validation accuracy: {val_acc[-1]:.4f}')\n",
        "print(f'Final validation loss: {val_loss[-1]:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "knC1MjaU5Hiq",
        "outputId": "f74ed2ee-c77c-4391-8b31-200e7a730069"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACjrUlEQVR4nOzdd3gUVRfH8W8KSQiQ0DvSOwhIbwKKIihVMRSlSFGKoIgK0hHBQpMmRRCU3i0gRRQB6SV0kd57CzWBZN4/7rsJIQmkbLKb5Pd5nn327uzMnbObBGbP3nuui2VZFiIiIiIiIiIiIgnI1dEBiIiIiIiIiIhI8qOklIiIiIiIiIiIJDglpUREREREREREJMEpKSUiIiIiIiIiIglOSSkREREREREREUlwSkqJiIiIiIiIiEiCU1JKREREREREREQSnJJSIiIiIiIiIiKS4JSUEhERERERERGRBKeklIjE2IkTJ3BxcWH69Omh2wYOHIiLi0u0jndxcWHgwIF2jalmzZrUrFnTrn2KiIiIOAtdf4lIUqSklEgS16BBA7y9vbl161aU+7Rs2RIPDw+uXr2agJHF3IEDBxg4cCAnTpxwdCiRWr58OS4uLmTPnp2QkBBHhyMiIiIOouuv+LV27VpcXFxYuHCho0MRkThSUkokiWvZsiX37t1jyZIlkT5/9+5dfv75Z1555RUyZMgQ6/P07duXe/fuxfr46Dhw4ACDBg2K9KJo1apVrFq1Kl7P/zSzZs0iT548nD9/nj///NOhsYiIiIjj6PpLRCR6lJQSSeIaNGhAmjRpmD17dqTP//zzz9y5c4eWLVvG6Tzu7u54eXnFqY+48PDwwMPDw2Hnv3PnDj///DM9evSgTJkyzJo1y2GxPM2dO3ccHYKIiEiSpusvEZHoUVJKJIlLmTIlTZo0Yc2aNVy6dCnC87NnzyZNmjQ0aNCAa9eu0bNnT0qWLEnq1Knx8fGhbt267N69+6nniaymQWBgIB9++CGZMmUKPceZM2ciHHvy5Ek6d+5M4cKFSZkyJRkyZKBp06bhvpGbPn06TZs2BaBWrVq4uLjg4uLC2rVrgchrGly6dIl27dqRJUsWvLy8KFWqFDNmzAi3j60+w/Dhw5k8eTL58+fH09OT8uXLs23btqe+bpslS5Zw7949mjZtSrNmzVi8eDH379+PsN/9+/cZOHAghQoVwsvLi2zZstGkSROOHj0auk9ISAjffvstJUuWxMvLi0yZMvHKK6+wffv2cDE/WlPC5vF6Ebafy4EDB2jRogXp0qWjWrVqAOzZs4c2bdqQL18+vLy8yJo1K++8806k0wjOnj1Lu3btyJ49O56enuTNm5dOnToRFBTEsWPHcHFxYdSoURGO27hxIy4uLsyZMyfa76WIiEhip+uvhLn+eppjx47RtGlT0qdPj7e3N5UqVWLZsmUR9hs7dizFixfH29ubdOnSUa5cuXAJxVu3bvHBBx+QJ08ePD09yZw5My+99BI7d+60W6wiyZW7owMQkfjXsmVLZsyYwfz58+natWvo9mvXrrFy5UqaN29OypQp2b9/P0uXLqVp06bkzZuXixcvMmnSJGrUqMGBAwfInj17jM7bvn17Zs6cSYsWLahSpQp//vknr776aoT9tm3bxsaNG2nWrBk5c+bkxIkTfPfdd9SsWZMDBw7g7e3N888/T7du3RgzZgyfffYZRYsWBQi9f9y9e/eoWbMmR44coWvXruTNm5cFCxbQpk0bbty4Qffu3cPtP3v2bG7dusW7776Li4sLX3/9NU2aNOHYsWOkSJHiqa911qxZ1KpVi6xZs9KsWTN69erFr7/+GnohBxAcHMxrr73GmjVraNasGd27d+fWrVusXr2affv2kT9/fgDatWvH9OnTqVu3Lu3bt+fhw4esX7+ezZs3U65cuWi//49q2rQpBQsWZOjQoViWBcDq1as5duwYbdu2JWvWrOzfv5/Jkyezf/9+Nm/eHHqRe+7cOSpUqMCNGzfo2LEjRYoU4ezZsyxcuJC7d++SL18+qlatyqxZs/jwww8jvC9p0qShYcOGsYpbREQksdL1V/xffz3JxYsXqVKlCnfv3qVbt25kyJCBGTNm0KBBAxYuXEjjxo0BmDJlCt26deONN96ge/fu3L9/nz179rBlyxZatGgBwHvvvcfChQvp2rUrxYoV4+rVq2zYsIGDBw/y3HPPxSlOkWTPEpEk7+HDh1a2bNmsypUrh9s+ceJEC7BWrlxpWZZl3b9/3woODg63z/Hjxy1PT09r8ODB4bYB1g8//BC6bcCAAdaj/6T4+/tbgNW5c+dw/bVo0cICrAEDBoRuu3v3boSYN23aZAHWjz/+GLptwYIFFmD99ddfEfavUaOGVaNGjdDHo0ePtgBr5syZoduCgoKsypUrW6lTp7YCAgLCvZYMGTJY165dC933559/tgDr119/jXCux128eNFyd3e3pkyZErqtSpUqVsOGDcPtN23aNAuwRo4cGaGPkJAQy7Is688//7QAq1u3blHuE9n7b/P4e2v7uTRv3jzCvpG973PmzLEAa926daHbWrVqZbm6ulrbtm2LMqZJkyZZgHXw4MHQ54KCgqyMGTNarVu3jnCciIhIUqfrLyM+rr/++usvC7AWLFgQ5T4ffPCBBVjr168P3Xbr1i0rb968Vp48eULf84YNG1rFixd/4vl8fX2tLl26PHEfEYkdTd8TSQbc3Nxo1qwZmzZtCjcke/bs2WTJkoUXX3wRAE9PT1xdzT8LwcHBXL16ldSpU1O4cOEYD09evnw5AN26dQu3/YMPPoiwb8qUKUPbDx484OrVqxQoUIC0adPGelj08uXLyZo1K82bNw/dliJFCrp168bt27f5+++/w+3v5+dHunTpQh9Xr14dMMO+n2bu3Lm4urry+uuvh25r3rw5v//+O9evXw/dtmjRIjJmzMj7778foQ/bqKRFixbh4uLCgAEDotwnNt57770I2x593+/fv8+VK1eoVKkSQOj7HhISwtKlS6lfv36ko7RsMb355pt4eXmFq6W1cuVKrly5wltvvRXruEVERBIrXX8Z8XX9FZ1YKlSoEFq2ACB16tR07NiREydOcODAAQDSpk3LmTNnnjhtMG3atGzZsoVz587FOS4RCU9JKZFkwlZI0zY//syZM6xfv55mzZrh5uYGmATEqFGjKFiwIJ6enmTMmJFMmTKxZ88ebt68GaPznTx5EldX19ApaTaFCxeOsO+9e/fo378/uXLlCnfeGzduxPi8j56/YMGCoRd5Nrbh5idPngy3/Zlnngn32HaB9GhSKSozZ86kQoUKXL16lSNHjnDkyBHKlClDUFAQCxYsCN3v6NGjFC5cGHf3qGdOHz16lOzZs5M+ffqnnjcm8ubNG2HbtWvX6N69O1myZCFlypRkypQpdD/b+3758mUCAgIoUaLEE/tPmzYt9evXD1d/YdasWeTIkYMXXnjBjq9EREQk8dD1lxEf11/RiSWy1/14LJ9++impU6emQoUKFCxYkC5duvDPP/+EO+brr79m37595MqViwoVKjBw4EC7JM5EREkpkWSjbNmyFClSJLTg9Jw5c7AsK9yqL0OHDqVHjx48//zzzJw5k5UrV7J69WqKFy9OSEhIvMX2/vvv88UXX/Dmm28yf/58Vq1axerVq8mQIUO8nvdRtgvDx1n/r78UlcOHD7Nt2zY2bNhAwYIFQ2+2b+XiYxW+qEZMBQcHR3nMo9+G2rz55ptMmTKF9957j8WLF7Nq1SpWrFgBEKv3vVWrVhw7doyNGzdy69YtfvnlF5o3bx7hwlRERCS50PXXk8X2+sueihYtyqFDh5g7dy7VqlVj0aJFVKtWLdyo9TfffJNjx44xduxYsmfPzjfffEPx4sX5/fffEyxOkaRKhc5FkpGWLVvSr18/9uzZw+zZsylYsCDly5cPfX7hwoXUqlWLqVOnhjvuxo0bZMyYMUbnyp07NyEhIaGjg2wOHToUYd+FCxfSunVrRowYEbrt/v373LhxI9x+MZm+ljt3bvbs2UNISEi4pMi///4b+rw9zJo1ixQpUvDTTz9FuLDasGEDY8aM4dSpUzzzzDPkz5+fLVu28ODBgyiLd+bPn5+VK1dy7dq1KEdL2b5FfPz9efzbxye5fv06a9asYdCgQfTv3z90++HDh8PtlylTJnx8fNi3b99T+3zllVfIlCkTs2bNomLFity9e5e333472jGJiIgkRbr+sv/1V3Rjiex1RxZLqlSp8PPzw8/Pj6CgIJo0acIXX3xB79698fLyAiBbtmx07tyZzp07c+nSJZ577jm++OIL6tatmzAvSCSJ0tfXIsmI7Vu5/v374+/vH+5bOjDfVj3+zdSCBQs4e/ZsjM9l+w96zJgx4baPHj06wr6RnXfs2LERRv6kSpUKiJiMiUy9evW4cOEC8+bNC9328OFDxo4dS+rUqalRo0Z0XsZTzZo1i+rVq+Pn58cbb7wR7vbxxx8DhH47+vrrr3PlyhXGjRsXoR/b63/99dexLItBgwZFuY+Pjw8ZM2Zk3bp14Z6fMGFCtOO2JdAef98f//m4urrSqFEjfv31V7Zv3x5lTADu7u40b96c+fPnM336dEqWLMmzzz4b7ZhERESSIl1/2f/6Kzrq1avH1q1b2bRpU+i2O3fuMHnyZPLkyUOxYsUAuHr1arjjPDw8KFasGJZl8eDBA4KDgyNMZ8ycOTPZs2cnMDAw/l+ISBKnkVIiyUjevHmpUqUKP//8M0CEi6LXXnuNwYMH07ZtW6pUqcLevXuZNWsW+fLli/G5SpcuTfPmzZkwYQI3b96kSpUqrFmzhiNHjkTY97XXXuOnn37C19eXYsWKsWnTJv744w8yZMgQoU83Nze++uorbt68iaenJy+88AKZM2eO0GfHjh2ZNGkSbdq0YceOHeTJk4eFCxfyzz//MHr0aNKkSRPj1/S4LVu2hC55HJkcOXLw3HPPMWvWLD799FNatWrFjz/+SI8ePdi6dSvVq1fnzp07/PHHH3Tu3JmGDRtSq1Yt3n77bcaMGcPhw4d55ZVXCAkJYf369dSqVSv0XO3bt+fLL7+kffv2lCtXjnXr1vHff/9FO3YfHx+ef/55vv76ax48eECOHDlYtWoVx48fj7Dv0KFDWbVqFTVq1KBjx44ULVqU8+fPs2DBAjZs2EDatGlD923VqhVjxozhr7/+4quvvorZGyoiIpIE6frLvtdfj1q0aFHoyKdHtW7dml69ejFnzhzq1q1Lt27dSJ8+PTNmzOD48eMsWrQodCTXyy+/TNasWalatSpZsmTh4MGDjBs3jldffZU0adJw48YNcubMyRtvvEGpUqVInTo1f/zxB9u2bQs3ykxEYskRS/6JiOOMHz/eAqwKFSpEeO7+/fvWRx99ZGXLls1KmTKlVbVqVWvTpk0RlvuNzpLElmVZ9+7ds7p162ZlyJDBSpUqlVW/fn3r9OnTEZYkvn79utW2bVsrY8aMVurUqa06depY//77r5U7d26rdevW4fqcMmWKlS9fPsvNzS3c8sSPx2hZlnXx4sXQfj08PKySJUuGi/nR1/LNN99EeD8ej/Nx77//vgVYR48ejXKfgQMHWoC1e/duy7LM8st9+vSx8ubNa6VIkcLKmjWr9cYbb4Tr4+HDh9Y333xjFSlSxPLw8LAyZcpk1a1b19qxY0foPnfv3rXatWtn+fr6WmnSpLHefPNN69KlSxFitv1cLl++HCG2M2fOWI0bN7bSpk1r+fr6Wk2bNrXOnTsX6es+efKk1apVKytTpkyWp6enlS9fPqtLly5WYGBghH6LFy9uubq6WmfOnInyfREREUlOdP31Q7h94nL9ZVmW9ddff1lAlLf169dblmVZR48etd544w0rbdq0lpeXl1WhQgXrt99+C9fXpEmTrOeff97KkCGD5enpaeXPn9/6+OOPrZs3b1qWZVmBgYHWxx9/bJUqVcpKkyaNlSpVKqtUqVLWhAkTnhijiESPi2UlYBU5ERFJ8sqUKUP69OlZs2aNo0MREREREREnpppSIiJiN9u3b8ff359WrVo5OhQREREREXFyGiklIiJxtm/fPnbs2MGIESO4cuUKx44dC12tRkREREREJDIaKSUiInG2cOFC2rZty4MHD5gzZ44SUiIiIiIi8lQaKSUiIiIiIiIiIglOI6VERERERERERCTBKSklIiIiIiIiIiIJzt3RATijkJAQzp07R5o0aXBxcXF0OCIiIuJELMvi1q1bZM+eHVfX5Pv9nq6XREREJCrRvV5SUioS586dI1euXI4OQ0RERJzY6dOnyZkzp6PDcBhdL4mIiMjTPO16SUmpSKRJkwYwb56Pj4+DoxERERFnEhAQQK5cuUKvF5IrXS+JiIhIVKJ7vaSkVCRsQ9B9fHx0kSUiIiKRSu5T1nS9JCIiIk/ztOul5FsIQUREREREREREHEZJKRERERERERERSXBKSomIiIiIiIiISIJTTak4CA4O5sGDB44OQ8SuUqRIgZubm6PDEBERERGReKDPsWIP9vrcqKRULFiWxYULF7hx44ajQxGJF2nTpiVr1qzJvoiviIiIiEhSoc+xYm/2+NyopFQs2P6QM2fOjLe3tz64S5JhWRZ3797l0qVLAGTLls3BEYmIiIiIiD3oc6zYiz0/NyopFUPBwcGhf8gZMmRwdDgidpcyZUoALl26RObMmTWVT0REREQkkdPnWLE3e31uVKHzGLLNvfX29nZwJCLxx/b7rbnmIiIiIiKJnz7HSnywx+dGJaViSUMdJSnT77eIiIiISNKj63yxJ3v8PikpJSIiIiLO6eFDR0cgIiIi8UhJKYm2mjVr8sEHH4Q+zpMnD6NHj37iMS4uLixdujTO57ZXPyKScP77D+rXhzfegIsXHR2N87IsR0cg4oQOHoTnnoNnn3V0JCIikgQk9c+yAwcOpHTp0vF6jviiQufJQP369Xnw4AErVqyI8Nz69et5/vnn2b17N8/G8MJv27ZtpEqVyl5hAuaPaenSpfj7+4fbfv78edKlS2fXc4kktBs34PJlKFjQ0ZHEr4cPYdQo6N8f7t832/75B+bMgZo17XuugAA4fNh8dnWG0egPH8LUqXDoENy5A3fvht1H1b53D55/Hv78E7SugMj/Zc0Ku3aZ9pUrkDGjY+MRERGH0GfZpE9JqWSgXbt2vP7665w5c4acOXOGe+6HH36gXLlyMf4jBsiUKZO9QnyqrFmzJti5nElQUBAeHh6ODkPs4N49qFjRjB5q1w5GjABfX0dHZX9798I778D27eZx7dpw/jzs3w8vvgiDB0Pv3uAax3G6lgVz58KHH5pRWC+/DBMmQP78cX8NsRUcDG3bwsyZMT923TqYNw9atLB/XCKJUrp0UKQI/PsvbN4Mr73m6IhERMQB9Fk26dP0vWTgtddeI1OmTEyfPj3c9tu3b7NgwQLatWvH1atXad68OTly5MDb25uSJUsyZ86cJ/b7+JDHw4cP8/zzz+Pl5UWxYsVYvXp1hGM+/fRTChUqhLe3N/ny5aNfv36hlfqnT5/OoEGD2L17Ny4uLri4uITG/PiQx7179/LCCy+QMmVKMmTIQMeOHbl9+3bo823atKFRo0YMHz6cbNmykSFDBrp06fLEVQGOHj1Kw4YNyZIlC6lTp6Z8+fL88ccf4fYJDAzk008/JVeuXHh6elKgQAGmTp0a+vz+/ft57bXX8PHxIU2aNFSvXp2jR48CEYeMAjRq1Ig2bdqEe08///xzWrVqhY+PDx07dnzq+2bz66+/Ur58eby8vMiYMSONGzcGYPDgwZQoUSLC6y1dujT9+vWL8v0Q+/riC5OQAjOSpkQJiOQLn0QrKAgGDYKyZU1CKm1amDYNVq2CLVugTRsICYG+faFePTNiLLaOHoVXXjEJHNu0wFWrzHs6dKiJJaGFhMB775mElJsbdO9uEnDDh8N338GMGbBgASxfDmvXwtatJlF3/DjY/gw//9wktkTk/ypXNvebNzs2DhERcRh9lo3eZ9nHhYSEMHjwYHLmzImnpyelS5cON9osKCiIrl27ki1bNry8vMidOzfDhg0DwLIsBg4cyDPPPIOnpyfZs2enW7du0T53TGmklB1YlpmCkdC8vaM3XcXd3Z1WrVoxffp0+vTpE1ohf8GCBQQHB9O8eXNu375N2bJl+fTTT/Hx8WHZsmW8/fbb5M+fnwoVKjz1HCEhITRp0oQsWbKwZcsWbt68GSEBA5AmTRqmT59O9uzZ2bt3Lx06dCBNmjR88skn+Pn5sW/fPlasWBGaDPKNZCjJnTt3qFOnDpUrV2bbtm1cunSJ9u3b07Vr13D/WP31119ky5aNv/76iyNHjuDn50fp0qXp0KFDpK/h9u3b1KtXjy+++AJPT09+/PFH6tevz6FDh3jmmWcAaNWqFZs2bWLMmDGUKlWK48ePc+XKFQDOnj3L888/T82aNfnzzz/x8fHhn3/+4WEMi7QOHz6c/v37M2DAgGi9bwDLli2jcePG9OnThx9//JGgoCCWL18OwDvvvMOgQYPYtm0b5cuXB2DXrl3s2bOHxYsXxyg2iZ1//4Wvvzbtfv1g9myTWKlb14wqGjHCJHESq+3bzevYu9c8btjQjFrKnt08TpUKfvjBTFHr0gVWroQyZcxIp2rVon+eoCDzXg0ebKYFenpCnz7QuDF88AGsWWMez5oFkybFrO+4sCyThPr+ezMCbNYs8POL/vE9e8K4ceb3ZP58aN48/mIVSVQqVzb/eGza5OhIRESSJkd9kIVof5jVZ9nofZZ93LfffsuIESOYNGkSZcqUYdq0aTRo0ID9+/dTsGBBxowZwy+//ML8+fN55plnOH36NKdPnwZg0aJFjBo1irlz51K8eHEuXLjA7t27o3XeWLGcwLhx46zcuXNbnp6eVoUKFawtW7ZEuW+NGjUsIMKtXr16ofu0bt06wvN16tSJdjw3b960AOvmzZsRnrt375514MAB6969e6Hbbt+2LPMXnbC327ej/ZKsgwcPWoD1119/hW6rXr269dZbb0V5zKuvvmp99NFHoY9r1Khhde/ePfRx7ty5rVGjRlmWZVkrV6603N3drbNnz4Y+//vvv1uAtWTJkijP8c0331hly5YNfTxgwACrVKlSEfZ7tJ/Jkydb6dKls24/8gYsW7bMcnV1tS5cuGBZlvkdyJ07t/Xw4cPQfZo2bWr5+flFGUtkihcvbo0dO9ayLMs6dOiQBVirV6+OdN/evXtbefPmtYKCgiJ9/vH3z7Isq2HDhlbr1q1DH+fOndtq1KjRU+N6/H2rXLmy1bJlyyj3r1u3rtWpU6fQx++//75Vs2bNKPeP7PdcYickxLJq1TJ/s/Xqmce3b1tW9+6W5eJitufIYVnLljk60pi7e9eyPvnEslxdzevImNGy5s41rzEqe/daVpEiZn83N8v68kvLCg5++rnWr7es4sXD/v178UXL+u+/sOdDQixr5kzLypQpbJ/27S3r6tW4v84nCQmxrI8/Djvn9Omx6+fzz83xRYta1iP/bNnFnTuWdfiwfft81LZtllW2rGVVr25Zb71lWX36WNbkyZa1YoVlHTxofk+SmiddJyQn8f4+7N1r/jBSp7b/H4aISDIT6fW9oz7IxvDDrD7LPv2z7OPnzp49u/XFF1+E26d8+fJW586dLcsynwdfeOEFKySSC/cRI0ZYhQoVivJz7aOe9LkxutcJDp++N2/ePHr06MGAAQPYuXMnpUqVok6dOly6dCnS/RcvXsz58+dDb/v27cPNzY2mTZuG2++VV14Jt9/Thu8ldUWKFKFKlSpMmzYNgCNHjrB+/XratWsHQHBwMJ9//jklS5Ykffr0pE6dmpUrV3Lq1Klo9X/w4EFy5cpFdtvQCKCybdj9I+bNm0fVqlXJmjUrqVOnpm/fvtE+x6PnKlWqVLjCdFWrViUkJIRDhw6FbitevDhuj1QNzpYtW5S/V2BGSvXs2ZOiRYuSNm1aUqdOzcGDB0Pj8/f3x83NjRo1akR6vL+/P9WrVydFihQxej2PK1euXIRtT3vf/P39efHFF6Pss0OHDsyZM4f79+8TFBTE7Nmzeeedd+IUp0TP7Nnw11/g5QVjx5ovhFKlgtGj4e+/oUABOHsWXn3V1CO6ccPREUfPhg1QurQZARYSYkb3HDhgRgg96UuvEiVg2zZo2dJMVevVCxo0gKtXI9//2jXo2BGqVzfT3TJlgp9+gtWrwxeMd3Exff77L7Rvb7Z9/70pSTNrVvytcDdwIHzzjWlPmgStW8eun/ffN6PlDh6EhQvtFZ352bz2mnmvJk2yX782Z86YFRZ37ID16830xS++MD+zV16BokXNF6GZM0P58mYlxo8+gjFjzGhBkScqWhTSpIHbt2HfPkdHIyIiDqLPsk//LPuogIAAzp07R9WqVcNtr1q1KgcPHgTMFEF/f38KFy5Mt27dWLVqVeh+TZs25d69e+TLl48OHTqwZMmSGM/+iQmHJ6VGjhxJhw4daNu2LcWKFWPixIl4e3uH/sI9Ln369GTNmjX0tnr1ary9vSMkpTw9PcPtF5/V7r29zfVSQt+8vWMWZ7t27Vi0aBG3bt3ihx9+IH/+/KEJlm+++YZvv/2WTz/9lL/++gt/f3/q1KlDkB2Ls2zatImWLVtSr149fvvtN3bt2kWfPn3seo5HPZ4ccnFxISQkJMr9e/bsyZIlSxg6dCjr16/H39+fkiVLhsaXMmXKJ57vac+7urpiPfbJOLJ5wY+vAhGd9+1p565fvz6enp4sWbKEX3/9lQcPHvDGG2888RiJuxs3oEcP0+7bF/LlC/989eqwe7cp1u3iAtOnQ/HisGxZ/MX08KGpY/TnnyZpM2CAmQ43apR5PG+eqXu0fr1Z+OrIEVO36e5dk9i5fdskUJ5/3tTIypYNfv7ZJN+iWy8ydWqTWJo82UzBW7bMTOd7tGyMZZk+ixaFKVPMtvbtTdLprbeiTnylT2/2X7cOihUztaveessUQj9yJG7v3eO+/NK8dwDffmsSMbHl62t+D8DUlnrCP1UxMmOGSYqCmTppzzpmd++aqZoXLphk4+zZ5j3p1MnUDSte3Pyswfwctm+HRYtg5Egz3bFYMfP7Z1uh0V5CQkwstuSkJGJubmaFCNAUPhGR+OCoD7Kx+DCrz7JP/iwbU8899xzHjx/n888/5969e7z55puhnw9z5crFoUOHmDBhAilTpqRz5848//zzMappFRMOrSkVFBTEjh076N27d+g2V1dXateuzaZoXnxMnTqVZs2aRfggv3btWjJnzky6dOl44YUXGDJkCBkyZIi0j8DAQAIDA0MfBwQExOh12EY+OLs333yT7t27M3v2bH788Uc6deoUOif3n3/+oWHDhrz11luAmVf733//UaxYsWj1XbRoUU6fPs358+fJli0bAJsfK0y6ceNGcufOTZ8+fUK3nTx5Mtw+Hh4eBD+l0m/RokWZPn06d+7cCf25//PPP7i6ulK4cOFoxRuZf/75hzZt2oQWCL99+zYnTpwIfb5kyZKEhITw999/U7t27QjHP/vss8yYMYMHDx5EOloqU6ZMnD9/PvRxcHAw+/bto1atWk+MKzrv27PPPsuaNWto27ZtpH24u7vTunVrfvjhBzw8PGjWrNlTE1kSd336wKVLULiwqRsUGW9v8yH99dfNSKnDh83IllatzGiqmObTLcusnn78OBw7FvH+1KnYF9N2dQV397BC4nGph+XiAh06mNEzTZuahFH16mbk1WuvQefOYFtnoFgxmDjRPB9d1aubpNrw4SbJ88cfJnHSty98/LFJhsXF6NFmFUEwiRh71H7s1s0kB/fvN8mbx75ribErV8xrBTMi78gR0+eGDVCqVNz6tixTvH7nTsiYEX75BfLmjXy/69fh5Mnwt+3bTeJz8GAzkm38eKhTJ24xgfk5f/KJ+dmDGbn30ktx71ccqHJl84PdtMmsJiAiIvaTWD7Ios+yMeHj40P27Nn5559/ws3y+eeff8LV2PLx8cHPzw8/Pz/eeOMNXnnlFa5du0b69OlJmTIl9evXp379+nTp0oUiRYqwd+9ennvuObvE+CiHJqWuXLlCcHAwWbJkCbc9S5Ys/Pvvv089fuvWrezbty/c6mdgpu41adKEvHnzcvToUT777DPq1q3Lpk2bwg2Bsxk2bBiDBg2K24tJBFKnTo2fnx+9e/cmICAg3KpvBQsWZOHChWzcuJF06dIxcuRILl68GO0/5Nq1a1OoUCFat27NN998Q0BAQLg/WNs5Tp06xdy5cylfvjzLli1jyZIl4fbJkycPx48fx9/fn5w5c5ImTRo8H/v02LJlSwYMGEDr1q0ZOHAgly9f5v333+ftt9+O8LsUEwULFmTx4sXUr18fFxcX+vXrFy4bnSdPHlq3bs0777wTWuj85MmTXLp0iTfffJOuXbsyduxYmjVrRu/evfH19WXz5s1UqFCBwoUL88ILL9CjRw+WLVtG/vz5GTlyJDeiMVcrOu/bgAEDePHFF8mfPz/NmjXj4cOHLF++nE8//TR0n/bt21O0aFHA/IMk8WvbNrPqGpii309LglStCv7+0L+/SVL9+KOZovbNN+ZD/40bcPPm0++vXYM7d558Lg8Pk0DImxdy5zaJg1u3It5u3w67BzMCJSjIHDNlin0+7JcubaZ+dehginz36GGmd1mWmfLYr59J6Hl4xLxvDw/47DOTmOjc2azQZys036uXmUoW0xGnYKbB2UY1DRgAj/yZxUnatKZg+8CBZiXD1183icDY+vRTMy2yZEkzCu2118yoqVdfNSsi5sgR+74//9ysJpgihUmgRZaQAnOtmz69uZUpE7bdssxx3buHrabYtKlJysUmLn9/83ptI899fMzjx0atS2Jkmz6hkVIiIsmaPsvGzMcff8yAAQPInz8/pUuX5ocffsDf359Zs2YBZsZatmzZKFOmDK6urixYsICsWbOSNm1apk+fTnBwMBUrVsTb25uZM2eSMmVKcufObbf4wnlq5ap4dPbsWQuwNm7cGG77xx9/bFWoUOGpx3fs2NEqWbLkU/c7evSoBVh//PFHpM/fv3/funnzZujt9OnTMSp0nphs3LjR4rHC8JZlWVevXrUaNmxopU6d2sqcObPVt29fq1WrVlbDhg1D93lScTjLMoXAq1WrZnl4eFiFChWyVqxYEaE43Mcff2xlyJDBSp06teXn52eNGjXK8vX1DX3+/v371uuvv26lTZvWAqwffvjBsiwrQj979uyxatWqZXl5eVnp06e3OnToYN26dSv0+datW4eL3bIsq3v37laNGjWifG+OHz9u1apVy0qZMqWVK1cua9y4cRFe871796wPP/zQypYtm+Xh4WEVKFDAmjZtWujzu3fvtl5++WXL29vbSpMmjVW9enXr6NGjlmVZVlBQkNWpUycrffr0VubMma1hw4ZFWuj80fc0uu+bZVnWokWLrNKlS1seHh5WxowZrSZNmkTop3r16lbx4sWjfA8efZ2J+ffc0R4+NIWfwbKeUH8+Sv/8Y1mFCsW+bqSLiymeXr26ZbVqZVkDB1rWjBmWtW6dZZ05E73C4o8KDrasgADLOnvWFBePRs3DGAsJsazx4y3Lw8O8hpdftqwjR+zb/+zZlpU5c9j75OtrWZ07W9bOndHvZ/r0sOM/+eTJRd1j4/p1ExdY1oIFse9n3bqwOP/5x2y7di2syHzp0uZnGhsLFoT1/f33sY/RskwMH34YViw/dWrLGjXKsh48iN7xx4+b4uq2RQNSpDCLCFy+HLe4nkaFzo0EeR+uXQv7hYvvH6yISBKWFK7v9Vm2RpTvzeOFzoODg62BAwdaOXLksFKkSGGVKlXK+v3330Ofnzx5slW6dGkrVapUlo+Pj/Xiiy9aO/9/UbxkyRKrYsWKlo+Pj5UqVSqrUqVKUeZS7FHo3KFJqcDAQMvNzS1CRftWrVpZDRo0eOKxt2/ftnx8fKzRo0dH61wZM2a0Jk6cGK19Y7r6nkhiEBISYuXPn98aMWLEU/fV73ncjB0blvT4/yIaMXb3rmV9+qlJTpUqZVk1alhWgwYmyfT++5bVr59lDR9ukgILFljW6tWWtXWrWWUtMf/Y/v3Xsv74w/7JHptr1yxryBDLyps3fCKvbFnL+u47y3rS/5lz54YlT7p1i78Y+/c35yhZMuYJRMuyrMDAsJUKO3QI/9yxY2GJuXr1op/8sdm507JSpjTHf/BBzGOLyq5dllWpUtjPo3Rpy9q0Ker9r1yxrB49wpKYYFnNm1vW/78DiHfOmJT6+++/rddee83Kli3bU1cLsizLWr9+vVWlShUrffr0lpeXl1W4cGFr5MiRMTpngr0Ptmzqr7/G73lERJIwXd9LfEj0SSnLsqwKFSpYXbt2DX0cHBxs5ciRwxo2bNgTj/vhhx8sT09P68qVK089x+nTpy0XFxfr559/jlZMSkpJUnPp0iVrzJgxVqpUqaxr1649dX/9nsfeuXOW5eNjPj+NH+/oaCQqwcEmkefnFz6x4e1tWW3amNFFjyadliyxLDe3sERPfCWkLMskzmy/Q4sWxfz4L780x2bMaFlXr0Z8fsuWsMRSp07Rfy3nz1tWzpzmuDp1Yp7QeprgYMuaNMmy0qULG/HXsWP413D3rnl9ttFkYFkvvGBZ27fbN5anccak1PLly60+ffpYixcvjlZSaufOndbs2bOtffv2WcePH7d++ukny9vb25o0aVK0z5lg70PbtuaH/dln8XseEZEkTNf3Eh+SRFJq7ty5lqenpzV9+nTrwIEDVseOHa20adNaF/4/vODtt9+2evXqFeG4atWqWX5+fhG237p1y+rZs6e1adMm6/jx49Yff/xhPffcc1bBggWt+/fvRysmJaUkqQGsjBkzWrNmzYrW/sn193z9ess6eDBufTRvbj47lStnpvGJ87t82bJGjrSsokXDj54qVsxsnzvXTAsDy3r77diNXoqpvn3N+UqVitn5jh8PSzjNmBH1fosXh015Gz786f3euxc2kqlwYTPNML5cumRZrVuH/RwyZTLTJn/4ISwpBpb17LOW9fvv8ZsgjIozJqUeFZ2kVGQaN25svfXWW9HeP8Heh8mTzQ+9Vq34PY+ISBKWXK/vJX7ZIykVhxKq9uHn58fw4cPp378/pUuXxt/fnxUrVoQW+Tp16lS4FcsADh06xIYNG2jXrl2E/tzc3NizZw8NGjSgUKFCtGvXjrJly7J+/foIRcZEkgvLsrh8+TItWrRwdChO648/zIptJUqYVdVis0z9H3/AnDmmOPXEiWY1c3F+GTOawuX798M//5hVEL294cABU3i9WTN48MAU4p42LW7Fx6Prww8hTRrYvRt+/jl6x1gWdO0K9+5BjRrw9ttR79u4sVmZEMwKfYsWPbnfjh1NsfR06eDXX2O34mJ0ZcoE06fD33+blRcvXzYr/bVtC2fOwDPPmIUAdu0yBdL/v/COxNGuXbvYuHFjuFV6HhcYGEhAQEC4W4KwFTvfuhUePkyYc4qIiEiCcLEsy3J0EM4mICAAX19fbt68iY+PT7jn7t+/z/Hjx8mbNy9eXl4OilAkfiW333PLgooVzYp5NoULw9Sp0V+9KzAQnn0W/vvPJAbGjo2fWCVhBASYBOOUKWZ1wMaNYd48s9pcQunbF774wqxQuHPn05MvS5ZAkyYmxt274f+LbUbJsuD992H8eLPS4dq15u/gcV9/bVayc3ODFSugdu3YvqKYCwoyK/INGmRi/Owz8/fl6H+WnnSd4AxcXFxYsmQJjRo1euq+OXPm5PLlyzx8+JCBAwfSr1+/KPcdOHBgpKsVx/v7EBJiMqIBASYbWbp0/J1LRCSJSm7X95IwnvR7Fd3rJYePlBIRcbSffzYJqVSpzEiYrFnh0CEzcqp7d7hz5+l9fP21SUhlzQpDhsR/zBK/fHzg3Xdh+3Y4d86MJErIhBSY0VKpU4O/P/zyy5P3vXULunUz7U8+eXpCCkySa/RoePVVMzKwfn04fjz8Pr/+Cr16mfa33yZsQgrAw8MkxM6dM6OkevZ0fEIqqVm/fj3bt29n4sSJjB49mjlz5kS5b+/evbl582bo7fTp0wkTpKtrWMZ08+aEOaeIiIgkCCWlYikkJMTRIYjEm+T0+x0cDLaBAd27mylCBw6Ye8uCMWOgZElYsybqPo4eNSNaAEaOBF/f+I9bEk62bI6ZIpYhgxnJBGak0JPGNQ8caJI2+fJBnz7RP4e7O8ydC2XKmGly9erB9evmuX37oEULc9733oPOnWP9UuIsbVozpVLsL2/evJQsWZIOHTrw4YcfMnDgwCj39fT0xMfHJ9wtwdim8G3alHDnFBFJgpLTdb7EP3v8PrnbIY5kxcPDA1dXV86dO0emTJnw8PDARQUtJImwLIugoCAuX76Mq6srHh4ejg4p3s2bZz58+/qaURhgZolMmwZ+fqaWzvHjZoRI+/amDs+jSSdbHZ/AQHjxRVN/SMReevQwidFdu8yopQYNIu7j729GMYGZipcyZczOkTo1/PabGYjy779mCuDMmWbk1O3bULOmiUH/1SV9ISEhBAYGOjqMyFWqZO6VlBIRiRV9jhV7sufnRiWlYsjV1ZW8efNy/vx5zp075+hwROKFt7c3zzzzDK4JUdHZgR48gAEDTPvjj00y6lF16piEVe/e5sP+99/D77+bIuavvWb2WbTI1Nnx8IAJE/TBXewrY0aT9PzqKzNaqn798L9jwcFmmmFwsCnE/sorsTtP9uywbBlUq2ZqSxUtaqYE5ssHCxcm/NRFibnbt29z5MiR0MfHjx/H39+f9OnT88wzz9C7d2/Onj3Ljz/+CMD48eN55plnKFKkCADr1q1j+PDhdLPNA3U2tqTU4cNw5Yr54xARkWjT51iJD/b43KhC55GITkEuy7J4+PAhwcHBCRydSPxyc3PD3d3dKb85uXrVTGmyl++/hw4dzGpfx46ZESNRWbcO2rUD22e+li1N7ahq1eDsWejf3yQNROzt8mXIm9fUNvv117CEKJgEaadOZqW+gwchR464nWvVKjOFLzjY9Ll5s1kBT8JzxkLna9eupVatWhG2t27dmunTp9OmTRtOnDjB2rVrARg7diyTJk3i+PHjuLu7kz9/fjp06MC7774b7QvLBH8fihY1w/ke/0MQEZFo0+dYsZenfW6M7nWCklKRcMaLTZHkrn9/+PxzM2pp6NC493f/PhQqBKdPm9W9Pvjg6cfcu2dGVo0YYRaDcnMzH97z5zcjqlSAWeLLp5+aYvrlysHWrWa01MWLZpXImzfN9D17DXCZPdvURhs2DF56yT59JjW6TjAS/H145x344QezDKOtkJ+IiIg4Ja2+JyJJxpIlJiEF5oPyzz/Hvc9Jk0xCKmdOU8Q5OlKmNImBTZugeHGTkAIztU8JKYlPPXuaQt/bt5sppAAffWQSUs89Z98i5C1amPMoISVOR8XORUREkhwlpUTEqR0+DG3amHb+/Oa+TRs4cSL2fd65Ezbaql+/mCeUKlSAHTtM8eepU03tKZH4lClTWOJp4ECzGuSsWWbE1MSJZhU9kSTPlpTauhUePnRsLCIiImIXSkqJiNO6c8esBBYQANWrw549ZoWwGzfMynhBQbHrd8wYuHTJJLnato1dH56e8P77ZjaJSELo2dOM1tu2zRQ1B5OoKl/esXGJJJhixcDHx/znsG+fo6MRERERO1BSSkSckmWZVcX27YOsWWHePDN9ad48s0re1q3wyScx7/fGDTMFD8yIE60qJolFliymqDnA9evm70JldSRZcXU130yApvCJiIgkEUpKiYhTmjDBTE9yc4P58yFbNrM9d26YMcO0v/3W1JuKiREjTGKqeHFo3tyuIYvEu48/NqOlwBTo9/V1bDwiCU51pURERJIUJaVExOls3gwffmjaX39tpu49qn59M5UJzPS7Y8ei1++lS+aDPJjC6W5u9olXJKFkzQrLl5vErJ+fo6MRcQAlpURERJIUJaVExKlcvmzq5Tx4AG+8EZacetzQoVClill97M03ITDw6X1/+aUpRVKuHDRqZNewRRJMzZrQqpUpci6S7Nim7x05Yv7DEBERkURNSSkRcRrBwWZK3ZkzULgwTJsW9QfvFClg7lzIkMGshGcbORWVM2fMlECAIUP0gV5EJFFKlw6KFjXtzZsdG4uIiIjEmZJSIuI0+vUzS92nSgWLF0OaNE/eP1cu+PFH0x43DhYsiHrfIUPMaKrq1eHll+0Xs4iIJLBKlcy9klIiIiKJnpJSIuIUfv4Zhg0z7alTzcrf0VGvHnz6qWm3a2dmdDzu2DHTJ5jVyjRKSkQkEVNdKRERkSRDSSkRcbgjR6B1a9Pu3j3mBZyHDIFq1eDWLVNf6v798M8PHAgPH8Irr0Qsmi4iIomMLSm1dav5x11EREQSLSWlRMSh7t6F1183BcurVoVvvol5H+7upr5Uxoywaxf06BH23P79MHOmaQ8ZYp+YRUTEgYoVAx8fs3LFvn2OjkZERETiQEkpEXEYy4JOnWDPHsicGebNMwXMYyNHjrDk03ffmb4A+vc352nSBMqWtU/cIiLiQK6uYavwaQqfiIhIoqaklIg4zKRJplC5m5tJIuXIEbf+6tSBzz4z7fbtzeipxYtNDanBg+Mer4iIOAnVlRIREUkSlJQSEYfYts3UjwJT4LxmTfv0O2gQ1KgBt29D8+ZmW8uWULy4ffoXEREnoKSUiIhIkqCklEgiFRLi6AjiZsAACAqCxo2hZ0/79evuDrNnQ6ZMYY8HDrRf/yIi4gRs0/eOHIHLlx0bi4iIiMSaklIiidDq1ZA2LXz0kaMjiZ0HD2DdOtMeONBMr7On7NnN1L00aeDjjyF/fvv2LyIiDpYuHRQtatqbNzs2FhEREYk1JaVEEpn9++GNN+DWLRg9Gg4dcnREMbdzp1k0KX16KFEifs7xwgtmRb+hQ+OnfxERcTBN4RMREUn0lJQSSUQuXYLXXoOAAFMcPCTETINLbP7+29xXr24WUYov9h6BJSIiTkRJKRERkURPSSmRROL+fWjUCE6cgAIFYNUqs33ePNizx77nCgqC2rWhVi14+NC+fUNYUqpGDfv3LSIiyYQtKbV1a/z8ZyUiIiLxTkkpkUTAsqBtW/NlcNq08NtvZnqan595vl8/+55v9GhYswbWrjXX+vYUHAwbNpi2klIiIhJrRYuCjw/cvQt79zo6GhEREYkFJaVEEoGBA03hbnd3WLwYChcO2+7qCr/8Yr/k0dmzMHhw2GPbiCx78fc30w99faFUKfv2LSIiyYira9gqfJrCJyIikigpKSXi5GbNCksSTZpkptTZFCkCrVqZdt++9jnfxx+bIuQpU5rHq1fbp1+bR+tJubnZt28REUlmbFP4tAKfiIhIoqSklIgT27AB3nnHtD/9NKz9qP79IUUKkzyyJXxia+1amDPHFAifPdts27LFrGJnL6onJSIidqNi5yIiIomaklIiTuroUWjc2BQdb9IEhg6NfL+8eaF9e9Pu29fUn4qNBw/g/fdN+733TFH1QoVMDai//opdn48LDoZ160xbSSkREYkz2/S9I0fg8mXHxiIiIiIxpqSUiBO6cQNeew2uXIFy5eCnn0zpjKj06QNeXmZkVWxrQE2YAPv2QYYMMGSI2fbyy+beXnWl9u41ry1NGihTxj59iohIMpYunSl4DprCJyIikggpKSXiZB48gDfegH//hZw5TRFzb+8nH5MjB3TubNqxGS114YKZBggwbBikT2/aL71k7u1VV8o2da9qVVO0XUREJM40hU9ERCTRUlJKxIlYFnTpAmvWQOrU8NtvkC1b9I799FNIlQq2b4eff47ZeXv1MivilSsXvm5VzZomeXTkCBw/HrM+I6N6UiIiYndKSomIiCRaSkqJOJGRI2HKFDNVb84cKFUq+sdmzgwffGDa/fqZ+k3RsXEjzJhh2uPGhV8Rz8cHKlUy7biOlgoJUT0pERGJB7ak1Nat8PChY2MRERGRGFFSSsRJ/PwzfPyxaY8YYWpKxdRHH4Gvr6kNNX/+0/cPDjYjswDatQurF/soe9WVOnAArl41UxHLlYtbXyIiIqGKFjX/+d29a4oXioiISKKhpJSIE9i7F1q0MNP3OnWC7t1j10+6dGGJrQEDnv6F8eTJ4O8PadOaWlKRsdWVWrMm+qOvIvNoPakUKWLfj4iISDiurmHfqmgKn4iISKKipJSIE/jyS/MFb+3aMGYMuLjEvq9u3SBjRjh8GH78Mer9rlwxq/YBfP45ZMoU+X7lypmk1Y0bpl5VbKmelIiIxBvVlRIREUmUlJQScbCAAFiyxLSHDo37qnRp0kDv3qY9aBAEBka+32efwfXrpm7Ve+9F3Z+7O7zwgmnHtq6UZSkpJSIi8chWAFFJKRERkURFSSkRB1u0CO7dgyJF7FdrqVMnyJ4dTp2C77+P+Py2bWHbx417eiIsrnWl/v0XLl0CLy8oXz52fYiIiETJNn3v6FHzH46IiIgkCkpKiTiYbYpdq1Zxm7b3qJQpoW9f0x4yxEwNtAkJga5dzeilt96CatWe3p+trtSmTXDrVszjsY2SqlwZPD1jfryIiMgTpUsHJUuatm2pVxEREXF6SkqJONDJk7B2rUlGtWxp377btYM8eeDCBZgwIWz7Dz+YVbPTpIGvv45eX/nyQf78pnD62rUxj0VT90RE4te6deuoX78+2bNnx8XFhaVLlz5x/8WLF/PSSy+RKVMmfHx8qFy5MitXrkyYYONLzZrm/q+/HBqGiIiIRJ+SUiIONHOmua9VC555xr59e3iYFfjAFFIPCDA1pHr1MtsGDoRs2aLfn220VEzrSqmelIhI/Ltz5w6lSpVi/Pjx0dp/3bp1vPTSSyxfvpwdO3ZQq1Yt6tevz65du+I50nhUq5a5V1JKREQk0XCxLMtydBDOJiAgAF9fX27evImPj4+jw5EkyrJMHan//oPp06F1a/uf4+FDKFECDh2CwYPh4kUYPx6KFQN/f0iRIvp9LVkCTZpA4cKmRlR0HT4MhQqZJNmNG2ZqoYhIYubs1wkuLi4sWbKERo0axei44sWL4+fnR//+/aO1v9O9D1evmqVkLcsME86SxdERiYiIJFvRvU7QSCkRB9m2zSSkvL1Nsic+uLubFfjATNX77jvTHjs2ZgkpMF9Au7qaBNepU9E/zjZKqlIlJaRERJxVSEgIt27dIn369FHuExgYSEBAQLibU8mQAZ591rRjM9dcREREEpySUiIOYitw3rixqe8UX5o2Ndfot2+bIudvvgkvvBDzftKmDVvcKCZT+DR1T0TE+Q0fPpzbt2/z5ptvRrnPsGHD8PX1Db3lypUrASOMJk3hExERSVSUlBJxgKAgmDPHtFu1it9zubrC55+btrc3DB8e+75iWlfKssK+rFZSSkTEOc2ePZtBgwYxf/58MmfOHOV+vXv35ubNm6G306dPJ2CU0WQrdq6RUiIiIomCklIiDrB8OVy7ZgqNv/hi/J+vfn1TVH3VKojLF9svv2zuV6+G4OCn73/8OJw5Y6YKVq4c+/OKiEj8mDt3Lu3bt2f+/PnUrl37ift6enri4+MT7uZ0nn/eLGl76BCcO+foaEREROQplJQScQDb1L233gI3t/g/n4sLtGwJVavGrZ8KFcxUw2vXIDoLNNmm7pUvb0ZpiYiI85gzZw5t27Zlzpw5vPrqq44Oxz7SpYMyZUxbo6VEREScnpJSIgns6lX47TfTju+pe/aWIkVYParoTOFTPSkRkYRx+/Zt/P398ff3B+D48eP4+/tz6v8rU/Tu3ZtWj/ynM3v2bFq1asWIESOoWLEiFy5c4MKFC9y8edMR4duXpvCJiIgkGk6RlBo/fjx58uTBy8uLihUrsnXr1ij3rVmzJi4uLhFuj37DZ1kW/fv3J1u2bKRMmZLatWtz+PDhhHgpkkSFhMCNG/bpa948ePDAfJFbooR9+kxItrpSq1Y9fV8lpUREEsb27dspU6YMZf4/SqhHjx6UKVOG/v37A3D+/PnQBBXA5MmTefjwIV26dCFbtmyht+7duzskfrtSsXMREZFEw93RAcybN48ePXowceJEKlasyOjRo6lTpw6HDh2KtNjm4sWLCQoKCn189epVSpUqRdOmTUO3ff3114wZM4YZM2aQN29e+vXrR506dThw4ABeXl4J8rok6Th0CBo1gtOnzeiguNZGsk3dS2yjpGxsdaX++Qfu3IFUqSLf79QpOHHCTE+sUiXBwhMRSZZq1qyJZVlRPj99+vRwj9cm5VFE1aubVT6OHDGFDXPmdHREIiIiEgWHj5QaOXIkHTp0oG3bthQrVoyJEyfi7e3NtGnTIt0/ffr0ZM2aNfS2evVqvL29Q5NSlmUxevRo+vbtS8OGDXn22Wf58ccfOXfuHEuXLk3AVyZJwW+/mTpK//5rEjDvvAP378e+v0OHYMsWk6hp3tx+cSakAgUgd24z2ss2EioytufKlTN1qERERBKEry+ULWvaSTn5JiIikgQ4NCkVFBTEjh07wq324urqSu3atdm0aVO0+pg6dSrNmjUj1f+Haxw/fpwLFy6E69PX15eKFStG2WdgYCABAQHhbpK8hYTAkCHQoAEEBEC1apA1q0lOff557PudOdPc16kDWbLYJ9aE5uISfhW+qGjqnoiIOIytrpSm8ImIiDg1hyalrly5QnBwMFke+3SeJUsWLly48NTjt27dyr59+2jfvn3oNttxMelz2LBh+Pr6ht5y5coV05ciScitW9C0KfTrB5YFXbrAmjUwYYJ5/quvorfy3ONCQuCnn0w7sU7ds4lOXSnbl9NKSomISIJTXSkREZFEweHT9+Ji6tSplCxZkgoVKsSpn969e3Pz5s3Q2+nTp+0UoSQ2R4+amlGLF4OHB0yZAuPGmXbjxiZZFRxspvE9eBCzvtevh5MnwcfHjMBKzF580YyYOnAAzp6N+PzZs+a9dHU1o8xEREQSVLVqZq788ePmP18RERFxSg5NSmXMmBE3NzcuXrwYbvvFixfJmjXrE4+9c+cOc+fOpV27duG2246LSZ+enp74+PiEu0nys3KlqX+0fz9ky2ZG+jwyCA+AsWMhQwbw94evv45Z/7YC52++CSlT2iNix0mf3rxXEPkUPtvUvTJlTBJOREQkQaVJE/YflepKiYiIOC2HJqU8PDwoW7Ysa9asCd0WEhLCmjVrqPyUJc4WLFhAYGAgb731VrjtefPmJWvWrOH6DAgIYMuWLU/tU5Iny4JvvoF69eDGDahUCbZvj3yVvSxZ4NtvTXvwYDNSKDru3oUFC0w7sU/ds3lSXSnVkxIREYfTFD4RERGn5/Dpez169GDKlCnMmDGDgwcP0qlTJ+7cuUPbtm0BaNWqFb17945w3NSpU2nUqBEZMmQIt93FxYUPPviAIUOG8Msvv7B3715atWpF9uzZadSoUUK8JElE7t6FFi3gk09Mzad27cwXqtmzR31Mixbw6qsQFGSm8QUHP/08P/9salXlzQtVq9otfIey1ZVavdq8d49SUkpERBzOlpTSSCkRERGn5e7oAPz8/Lh8+TL9+/fnwoULlC5dmhUrVoQWKj916hSuruFzZ4cOHWLDhg2siqLK8ieffMKdO3fo2LEjN27coFq1aqxYsQIvL694fz2SeJw4YepE+fuDuzuMGQPvvWdqJT2JiwtMnAjFi8OWLea4Dz988jG2qXtvv23qLCUFlStDqlRw+TLs2QOlS5vtFy7AoUPmfape3aEhiohIclalivkP/uRJU1sqb15HRyQiIiKPcbEsy3J0EM4mICAAX19fbt68qfpSSdSqVWbE09WrkDkzLFwY8wTKlCnQsaOpD7V3L+TPH/l+589DzpxmNNHhw1CgQNzjdxavvQbLlpkVCT/5xGybPx/8/EySKjarFIqIODtdJxiJ4n2oWhU2boSpU83wZhEREUkQ0b1OSCJjNkSi5++/4YUXoE4dk5AqW9bUj4rNiJ727U1f9+6Z9uNT2GxmzzbPVa6ctBJSEHldKU3dExERp6EpfCIiIk5NSSlJ8iwL1qwxSZKaNU290xQpoGtXWL8ecuWKXb8uLma0lLe3udadMiXy/X76ydwnlQLnj7LVlVq/3iTnIOy6X0kpERFxuJo1zf1ff5kLAhEREXEqSkpJkmVZsHIlVKsGtWvDunXg4QGdO8ORIzB2rJl6Fxf58sHQoab98cdw+nT453fvNjcPD3jzzbidyxkVKWKmJgYGmsTU5cthKxKqnpSIiDhclSrmm6gzZ+DoUUdHIyIiIo9RUkqSHMuC5cvNdLlXXjGlJLy8oFs3OHYMxo+HZ56x3/m6djXnunUL3n03/BextlFS9etD+vT2O6ezcHEJm8K3apVJ/AGUKAEZMzouLhEREcAMZ65UybQ1hU9ERMTpKCklSYZlwS+/QPny8OqrZmW8lCnNynjHjsG330KOHPY/r5sbTJsGnp7w++8wc6bZ/vAhzJpl2klx6p6NbQrf6tWqJyUiIk7o0Sl8IiIi4lSUlJIkYflyeO45aNgQduwwX4x+/LFZAXrkSMiWLX7PX6QIDBhg2t27w4UL8Mcf5j5jRjNiK6mqXduMmNqzB5YuNduUlBIREadhK3auulIiIiJOx93RAYjE1a+/QoMGpp06tZlO16MHZMqUsHH07AkLFsCuXSYGDw+zvXnzsHZSlDEjlCkDO3eG1dR6/nnHxiQiIhKqcmUznPn8eTh8GAoVcnREIiIi8n8aKSWJ2qlT0Lq1ab/9Npw4AcOGJXxCCkwd1WnTwN0dFi2CefPM9qQ8dc/GVlcKoGhRyJLFcbGIiIiE4+UVVldKU/hEREScipJSkmg9eGBGIV2/DuXKwfffQ4YMjo2pdGno1cu0Q0LMtL6yZR0aUoKw1ZUCTd0TEREn9OgUPhEREXEaSkpJojVggFlZz8fHjEpylilyfftCsWKm3bq1qbeU1FWtaorKg5JSIiLihGxJqbVrVVdKRETEiaimlCRKq1bBl1+a9vffQ758jo3nUZ6esGIF/PwzdOzo6GgShqcnDB5srvXr13d0NCIiIo+pWNFM47t4Ef7918w1FxEREYfTSClJdM6fN/WjLAveew+aNnV0RBHlyhW+2Hly0LMn/PYbpErl6EhEREQe4+kJVaqYtqbwiYiIOA0lpSRRCQ6Gt96CS5fg2Wdh5EhHRyQiIiKJwqNT+ERERMQpKCklicrQofDnn2Y0zrx5YXWMRERERJ6oZk1zr7pSIiIiTkNJKUk0/v4bBg407e++MyvbiYiIiERLhQrg7Q2XL8P+/Y6ORkRERFBSShLA9eumCPbGjbHv4/JlaNECQkKgTRtTU0pEREQk2jw8zHKxoLpSIiIiTkJJKYl33bvDgAHmOrBxY7PoTUyEhEDr1nDunBkdNW5c/MQpIiIiSdyjU/hERETE4ZSUknh15AjMmmXarq6wdCmUKAHvvmtW0YuOkSPh99/NSs7z52t1NxEREYmlR4udh4Q4NBQRERFRUkri2RdfmGu+evVg715o0MCsoDd5MhQoAP36QUBA1Mdv3gy9e5v2t99CyZIJE7eIiIgkQeXKmW+3rl0zFyYiIiLiUEpKSbw5dgx++sm0+/eHYsXg559h3TqoVAnu3oUhQ0xyauxYCAoKf/z169CsGTx8CH5+0KFDwr8GERERSUJSpIBq1UxbU/hEREQcTkkpiTdDh5pRUXXqQMWKYdurVzdFzxctgkKFTBHzbt1M0mrePLNKs2VBu3Zw8iTkz29GVrm4OO61iIiISBJhm8KnYuciIiIOp6SUxIsTJ2DGDNMeMCDi8y4u0KQJ7NsH330HWbLA0aNmZFSFCvDhh7BkiflCc9488PFJ0PBFREQkqbIlpf7+23x7JiIiIg6jpJTEi2HDzLS7l16CypWj3i9FCnjvPVMQfdAgSJ0atm839aMAvvkGypZNmJhFREQkGXjuOUiTBm7cgD17HB2NiIhIsqaklNjdqVPwww+m3b9/9I5Jndrse+QIdOkC7u7QvLmZ1iciIiJiN+7uppYAaAqfiIiIgykpJXb35Zfw4AG88EJYLdHoypIFxo2DO3dg1izVkRIREZF4oLpSIiIiTkFJKbGrM2dg6lTTju4oqch4eCghJSIiIvGkZk1zv26d6kqJiIg4kJJSYldffQVBQVCjhrmJiIhI/Fu3bh3169cne/bsuLi4sHTp0ifuf/78eVq0aEGhQoVwdXXlgw8+SJA4nUaZMuDrCwEBsHOno6MRERFJtpSUErs5dw6mTDHtuIySEhERkZi5c+cOpUqVYvz48dHaPzAwkEyZMtG3b19KlSoVz9E5ITc3qF3btBctcmwsIiIiyZi7owOQpOOrryAw0NSRspVqEBERkfhXt25d6tatG+398+TJw7f/X+p22rRp8RWWc2ve3CSk5syBoUPBVd/VioiIJDT97yt2cf48TJ5s2v37qx6UiIhIUhMYGEhAQEC4W6JWrx74+JhlgzdudHQ0IiIiyZKSUmIX33wD9+9D5cpho+FFREQk6Rg2bBi+vr6ht1y5cjk6pLhJmRKaNDHt2bMdG4uIiEgypaSUxNnFizBxomkPGKBRUiIiIklR7969uXnzZujt9OnTjg4p7lq0MPfz58ODB46NRUREJBlSUkribPhwuHcPKlSAl192dDQiIiISHzw9PfHx8Ql3S/Rq1YIsWeDqVVi92tHRiIiIJDsxTkrlyZOHwYMHc+rUqfiIRxKZy5dhwgTT1igpERERSVTc3cHPz7Q1hU9ERCTBxTgp9cEHH7B48WLy5cvHSy+9xNy5cwkMDIyP2CQRGDEC7t6FcuUgBov+iIiIiB3dvn0bf39//P39ATh+/Dj+/v6hXyL27t2bVq1ahTvGtv/t27e5fPky/v7+HDhwIKFDdzzbFL6lS+HOHYeGIiIikty4WJZlxebAnTt3Mn36dObMmUNwcDAtWrTgnXfe4bnnnrN3jAkuICAAX19fbt68mTSGpseTK1cgTx5z/fbLL1C/vqMjEhERiX/OeJ2wdu1aatWqFWF769atmT59Om3atOHEiROsXbs29DmXSIY3586dmxMnTkTrnM74PsSKZUGBAnDsGMyZA82aOToiERGRRC+61wmxTkrZPHjwgAkTJvDpp5/y4MEDSpYsSbdu3Wjbtm2kFzuJQZK5yIpnffrA0KFQpgzs2KGpeyIikjzoOsFIUu9Dv34wZIj5hu2XXxwdjYiISKIX3euEWBc6f/DgAfPnz6dBgwZ89NFHlCtXju+//57XX3+dzz77jJYtW8a2a0kErl2DsWNNu39/JaREREQkEbNN4fv9d1P0XERERBKEe0wP2LlzJz/88ANz5szB1dWVVq1aMWrUKIoUKRK6T+PGjSlfvrxdAxXnMno03LoFpUpBw4aOjkZEREQkDooWhdKlwd8fFi2Cjh0dHZGIiEiyEOORUuXLl+fw4cN89913nD17luHDh4dLSAHkzZuXZpqPn2Rdvw7ffmva/fpplJSIiIgkAbbRUlqFT0REJMHEeKTUsWPHyJ079xP3SZUqFT/88EOsgxLnNnYsBARAiRLQuLGjoxERERGxg2bN4JNPYN06OH0acuVydEQiIiJJXoxHSl26dIktW7ZE2L5lyxa2b99ul6DEeQUFwYQJpv3ZZ+Aa66pkIiIiIk4kVy54/nmzGt+8eY6ORkREJFmIcUqhS5cunD59OsL2s2fP0qVLF7sEJc5r4UK4eBGyZ4c33nB0NCIiIiJ2pCl8IiIiCSrGSakDBw7w3HPPRdhepkwZDhw4YJegxHmNG2fu33sPUqRwbCwiIiIidvXGG+DuDrt2wcGDjo5GREQkyYtxUsrT05OLFy9G2H7+/Hnc3WNcokoSkR07YNMmk4zq0MHR0YiIiIjYWYYM8Morpj1njmNjERERSQZinJR6+eWX6d27Nzdv3gzdduPGDT777DNeeukluwYnzsU2SqppU8ia1bGxiIiIiMSLR6fwWZZjYxEREUniYjy0afjw4Tz//PPkzp2bMmXKAODv70+WLFn46aef7B6gOIcrV8K+MOza1bGxiIiIiMSbBg3A2xuOHoVt26BCBUdHJCIikmTFeKRUjhw52LNnD19//TXFihWjbNmyfPvtt+zdu5dcWjo3yZo6FQIDoWxZqFTJ0dGIiIiIxJNUqaBRI9NWwXMREZF4FasiUKlSpaJjx472jkWcVHAwTJhg2l27gouLY+MRERERiVctWpiE1Ny5MGIEuLk5OiIREZEkKdaVyQ8cOMCpU6cICgoKt71BgwZxDkqcy6+/wqlTpvann5+joxERERGJZy+/bC58Ll6Ev/6C2rUdHZGIiEiSFOPpe8eOHaNUqVKUKFGCV199lUaNGtGoUSMaN25M48aNYxzA+PHjyZMnD15eXlSsWJGtW7c+cf8bN27QpUsXsmXLhqenJ4UKFWL58uWhzw8cOBAXF5dwtyJFisQ4LgljK3Devj2kTOnYWERERETiXYoUZmUX0BQ+ERGReBTjpFT37t3Jmzcvly5dwtvbm/3797Nu3TrKlSvH2rVrY9TXvHnz6NGjBwMGDGDnzp2UKlWKOnXqcOnSpUj3DwoK4qWXXuLEiRMsXLiQQ4cOMWXKFHLkyBFuv+LFi3P+/PnQ24YNG2L6MuX/Dh6ENWvA1RU6dXJ0NCIiIknL6dOnOXPmTOjjrVu38sEHHzB58mQHRiUANG9u7hctgvv3HRuLiIhIEhXjpNSmTZsYPHgwGTNmxNXVFVdXV6pVq8awYcPo1q1bjPoaOXIkHTp0oG3bthQrVoyJEyfi7e3NtGnTIt1/2rRpXLt2jaVLl1K1alXy5MlDjRo1KFWqVLj93N3dyZo1a+gtY8aMMX2Z8n/jx5v7Bg0gd27HxiIiIpLUtGjRgr/++guACxcu8NJLL7F161b69OnD4MGDHRxdMletGuTMCQEB8MiofBEREbGfGCelgoODSZMmDQAZM2bk3LlzAOTOnZtDhw5Fu5+goCB27NhB7Ufm6Lu6ulK7dm02bdoU6TG//PILlStXpkuXLmTJkoUSJUowdOhQgoODw+13+PBhsmfPTr58+WjZsiWnTp16YiyBgYEEBASEu4m5Bpsxw7S7dnVsLCIiIknRvn37qFChAgDz58+nRIkSbNy4kVmzZjF9+nTHBpfcubqGjZbSFD4REZF4EeOkVIkSJdi9ezcAFStW5Ouvv+aff/5h8ODB5MuXL9r9XLlyheDgYLJkyRJue5YsWbhw4UKkxxw7doyFCxcSHBzM8uXL6devHyNGjGDIkCGh+1SsWJHp06ezYsUKvvvuO44fP0716tW5detWlLEMGzYMX1/f0FuuXLmi/TqSshkz4PZtKFoUXnjB0dGIiIgkPQ8ePMDT0xOAP/74I3TBmCJFinD+/HlHhiZgVuED+O03uHnTsbGIiIgkQTFOSvXt25eQkBAABg8eHJr0Wb58OWPGjLF7gI8KCQkhc+bMTJ48mbJly+Ln50efPn2YOHFi6D5169aladOmPPvss9SpU4fly5dz48YN5s+fH2W/vXv35ubNm6G306dPx+vrSAxCQsIKnHftCi4ujo1HREQkKSpevDgTJ05k/fr1rF69mldeeQWAc+fOkSFDBgdHJ5QqZb6dCwyEJUscHY2IiEiS4x7TA+rUqRPaLlCgAP/++y/Xrl0jXbp0uMQgc5ExY0bc3Ny4ePFiuO0XL14ka9askR6TLVs2UqRIgZubW+i2okWLcuHCBYKCgvDw8IhwTNq0aSlUqBBHjhyJMhZPT8/QbynFWLMG/vsP0qSBt992dDQiIiJJ01dffUXjxo355ptvaN26dWidzF9++SV0Wp84kIuLGS3Vr5+ZwtemjaMjEhERSVJiNFLqwYMHuLu7s2/fvnDb06dPH6OEFICHhwdly5ZlzZo1odtCQkJYs2YNlStXjvSYqlWrcuTIkdCRWgD//fcf2bJlizQhBXD79m2OHj1KtmzZYhRfcjd2rLlv08YkpkRERMT+atasyZUrV7hy5Uq4hV46duwYbiS4OJCtrtSaNRBFiQkRERGJnRglpVKkSMEzzzwTobB4bPXo0YMpU6YwY8YMDh48SKdOnbhz5w5t27YFoFWrVvTu3Tt0/06dOnHt2jW6d+/Of//9x7Jlyxg6dChdunQJ3adnz578/fffnDhxgo0bN9K4cWPc3NxobrugkKc6ftyUTgB45K0VERERO7t37x6BgYGkS5cOgJMnTzJ69GgOHTpE5syZHRydAJA/P1SsaGobPKEchIiIiMRcjGtK9enTh88++4xr167F+eR+fn4MHz6c/v37U7p0afz9/VmxYkVo8fNTp06FK/KZK1cuVq5cybZt23j22Wfp1q0b3bt3p1evXqH7nDlzhubNm1O4cGHefPNNMmTIwObNm8mUKVOc400uvvsOLAtefhkKF3Z0NCIiIklXw4YN+fHHHwG4ceMGFStWZMSIETRq1IjvvvvOwdFJKFvBc63CJyIiYlculmVZMTmgTJkyHDlyhAcPHpA7d25SpUoV7vmdO3faNUBHCAgIwNfXl5s3b+Lj4+PocBLU3buQMydcvw6//AL16zs6IhEREediz+uEjBkz8vfff1O8eHG+//57xo4dy65du1i0aBH9+/fn4MGDdora/pLV9dKFC5AjhxktdeSIGT0lIiIiUYrudUKMC503atQoLnGJk5szxySk8uSBevUcHY2IiEjSdvfuXdL8v3jjqlWraNKkCa6urlSqVImTJ086ODoJlTUrvPgirF4NU6fC0KGOjkhERCRJiHFSasCAAfERhzgBy4Jx40y7c2d4ZJFDERERiQcFChRg6dKlNG7cmJUrV/Lhhx8CcOnSpaQ/+iix6dTJJKUmTIBevUA/HxERkTiLcU0pSbo2bgR/f/DygnbtHB2NiIhI0te/f3969uxJnjx5qFChQugKxKtWraJMmTIOjk7CadjQFNu8eRMmTXJ0NCIiIklCjJNSrq6uuLm5RXmTxMs2SqplS0if3rGxiIiIJAdvvPEGp06dYvv27axcuTJ0+4svvsioUaMcGJlE4OoKn35q2qNGQWCgY+MRERFJAmI8fW/JkiXhHj948IBdu3YxY8YMBg0aZLfAJGGdOwcLF5p2ly6OjUVERCQ5yZo1K1mzZuXMmTMA5MyZkwoVKjg4KolUy5bQrx+cPQs//QTt2zs6IhERkUQtxkmphg0bRtj2xhtvULx4cebNm0c7zftKlCZPhocPoWpV0GwBERGRhBESEsKQIUMYMWIEt2/fBiBNmjR89NFH9OnTB1dXVVpwKh4e8NFH0KMHfP01tG2rIpwiIiJxYLcrnUqVKrFmzRp7dScJKCgorDTC++87NhYREZHkpE+fPowbN44vv/ySXbt2sWvXLoYOHcrYsWPp16+fo8OTyHToAOnSweHD8NgMAhEREYkZuySl7t27x5gxY8iRI4c9upMEtngxXLgA2bJB48aOjkZERCT5mDFjBt9//z2dOnXi2Wef5dlnn6Vz585MmTKF6dOnOzo8iUzq1GHf4n35pVm+WERERGIlxtP30qVLh4uLS+hjy7K4desW3t7ezJw5067BScIYM8bcv/uuGZUuIiIiCePatWsUKVIkwvYiRYpw7do1B0Qk0fL++/DNN7BjB6xZA7VrOzoiERGRRCnGSalRo0aFS0q5urqSKVMmKlasSLp06ewanMS/LVtg0yZIkQI6dnR0NCIiIslLqVKlGDduHGNs3xD937hx43j22WcdFJU8VcaMpsj52LFmtJSSUiIiIrES46RUmzZt4iEMcRTbatPNm5vpeyIiIpJwvv76a1599VX++OMPKleuDMCmTZs4ffo0y5cvd3B08kQffQQTJpiRUtu3Q7lyjo5IREQk0YlxTakffviBBQsWRNi+YMECZsyYYZegJGGcOgULF5r2hx86NhYREZHkqEaNGvz33380btyYGzducOPGDZo0acL+/fv56aefot3PunXrqF+/PtmzZ8fFxYWlS5c+9Zi1a9fy3HPP4enpSYECBVTDKqZy54YWLUz7q68cG4uIiEgiFeOk1LBhw8iYMWOE7ZkzZ2bo0KF2CUoSxrhxEBwMtWpB6dKOjkZERCR5yp49O1988QWLFi1i0aJFDBkyhOvXrzN16tRo93Hnzh1KlSrF+PHjo7X/8ePHefXVV6lVqxb+/v588MEHtG/fnpUrV8b2ZSRPn3xi7hctgv/+c2wsIiIiiVCMp++dOnWKvHnzRtieO3duTp06ZZegJP7dvg2TJ5u2RkmJiIgkbnXr1qVu3brR3n/ixInkzZuXESNGAFC0aFE2bNjAqFGjqFOnTnyFmfSUKAH168Ovv5rC51OmODoiERGRRCXGI6UyZ87Mnj17ImzfvXs3GTJksEtQEv+mT4ebN6FgQXj1VUdHIyIiIglp06ZN1H6sOHedOnXYtGmTgyJKxHr1MvczZsDZs46NRUREJJGJcVKqefPmdOvWjb/++ovg4GCCg4P5888/6d69O82aNYuPGMXOQkLg229Nu3t3cI3xb4GIiIgkZhcuXCBLlizhtmXJkoWAgADu3bsX6TGBgYEEBASEuwlQpQpUrw4PHsDo0Y6ORkREJFGJ8fS9zz//nBMnTvDiiy/i7m4ODwkJoVWrVqoplUj89hscOQJp00Lr1o6ORkREJPlp0qTJE5+/ceNGwgQSA8OGDWPQoEGODsM59eoF69fDxInw2WeQLp2jIxIREUkUYpyU8vDwYN68eQwZMgR/f39SpkxJyZIlyZ07d3zEJ/Fg1Chz37EjpE7t2FhERESSI19f36c+36pVq3g7f9asWbl48WK4bRcvXsTHx4eUKVNGekzv3r3p0aNH6OOAgABy5coVbzEmKnXrQsmSsHcvTJgAffo4OiIREZFEIcZJKZuCBQtSsGBBe8YiCcDfH9auBTc36NrV0dGIiIgkTz/88INDz1+5cmWWL18ebtvq1aupXLlylMd4enri6ekZ36ElTi4uZrRUy5amRsKHH4K3t6OjEhERcXoxrib0+uuv89VXX0XY/vXXX9O0aVO7BCXxxzZKqmlT0JebIiIiScPt27fx9/fH398fgOPHj+Pv7x+6MnLv3r3Djbx67733OHbsGJ988gn//vsvEyZMYP78+XyoJXlj7803IU8euHwZHJx0FBERSSxinJRat24d9erVi7C9bt26rFu3zi5BSfw4fx7mzDFtXXOKiIgkHdu3b6dMmTKUKVMGgB49elCmTBn69+8PwPnz50MTVAB58+Zl2bJlrF69mlKlSjFixAi+//576tSp45D4kwR3d+jZ07SHD4eHDx0bj4iISCIQ4+l7t2/fxsPDI8L2FClSaBUWJzd+vFkYpkoVqFDB0dGIiIiIvdSsWRPLsqJ8fvr06ZEes2vXrniMKhlq2xYGDYITJ2D+fGjRwtERiYiIOLUYj5QqWbIk8+bNi7B97ty5FCtWzC5Bif3du2cWhAF4pEapiIiIiNiLtzd0727aX34JT0gUioiISCxGSvXr148mTZpw9OhRXnjhBQDWrFnD7NmzWbhwod0DFPv46Se4etWUOmjUyNHRiIiIiCRRnTubhNTevfD77xBJ2QsRERExYjxSqn79+ixdupQjR47QuXNnPvroI86ePcuff/5JgQIF4iNGiSPLgtGjTbtbN7PynoiIiIjEg3Tp4L33TPvLLx0bi4iIiJOLcVIK4NVXX+Wff/7hzp07HDt2jDfffJOePXtSqlQpe8cndrByJRw8CGnSQLt2jo5GREREJIn78EPw8ID16+GffxwdjYiIiNOKVVIKzCp8rVu3Jnv27IwYMYIXXniBzZs32zM2sZNRo8x9u3bg4+PYWERERESSvOzZoVUr0+7TR7WlREREohCjpNSFCxf48ssvKViwIE2bNsXHx4fAwECWLl3Kl19+Sfny5eMrToml/fth1SpwdTVT90REREQkAfTtCylTwt9/w+zZjo5GRETEKUU7KVW/fn0KFy7Mnj17GD16NOfOnWPs2LHxGZvYga2WVKNGkDevIyMRERERSUZy5zaJKYCPPoKbNx0bj4iIiBOKdlLq999/p127dgwaNIhXX30VN1XLdnqXL5tV98CUNhARERGRBPTRR1CoEFy8CP37OzoaERERpxPtpNSGDRu4desWZcuWpWLFiowbN44rV67EZ2wSRxMnQmAglCsHVas6OhoRERGRZMbTE8aNM+1x48Df36HhiIiIOJtoJ6UqVarElClTOH/+PO+++y5z584le/bshISEsHr1am7duhWfcUoMBQbC+PGm/eGH4OLi2HhEREREkqWXXoKmTSEkBLp0MfciIiICxGL1vVSpUvHOO++wYcMG9u7dy0cffcSXX35J5syZadCgQXzEKLEwZ44ZKZ4jh7kOEhEREREHGTkSUqWCjRthxgxHRyMiIuI0YpyUelThwoX5+uuvOXPmDHPmzLFXTBJHlgWjRpl2166QIoVj4xERERFJ1nLmhIEDTfuTT+DaNYeGIyIi4izilJSycXNzo1GjRvzyyy/26E7i6K+/YM8e8PaGjh0dHY2IiIiI0L07FCsGV65Anz6OjkZERMQp2CUpJc7FNkqqTRtIn96hoYiIiIgImKHrtoKfkybBtm2OjUdERMQJKCmVxAQEwPLlpt2tm2NjEREREZFH1KwJLVuaWgudO0NwsKMjEhERcSglpZKYTZvMoi758kHhwo6ORkRERETCGT4cfHxg+3b4/ntHRyMiIuJQSkolMevWmfvq1R0bh4iIiIhEImtW+Pxz0+7dGy5fdmw8IiIiDqSkVBKzfr25f/55x8YhIiIiIlHo3BlKlYLr16FXL0dHIyIi4jBKSiUh9+/Dli2mrZFSIiIiIk7K3R0mTDDtadNM/QUREZFkSEmpJGTbNggKgixZoEABR0cjIiIiIlGqUgXatjXtzp3h4UPHxiMiIuIASkolIbZ6Us8/Dy4ujo1FRERERJ7iq68gXTrw94fvvnN0NCIiIglOSakkxFZPSlP3RERERBKBTJlg6FDT7tsXLlxwbDwiIiIJTEmpJOLhQ/jnH9NWkXMRERGRRKJDByhXDgIC4OOPHR2NiIhIglJSKonYvRtu3wZfXyhRwtHRiIiIiEi0uLmZoucuLjBzJkyfDv/9B/fuOToyERGReOfu6ADEPmz1pKpVM9c2IiIiIpJIlC8PHTvCpElhxc/BTO975pmwW+7c4R9nygSu+o5ZREQSLyWlkgjVkxIRERFJxL76yiyjvHkznDoFd+7A5cvmtmNH5Md4esKbb8LUqZAiRcLGKyIiYgdKSiUBlhWWlFI9KREREZFEyNcXpk0zbcuC69dNcsp2O306/ONz5yAwEH76CVKnhvHjtfyyiIgkOkpKJQH//gtXrkDKlFC2rKOjEREREZE4cXGB9OnNrXTpyPd58ACWLgU/P/juOyhaFN5/PyGjFBERiTOHT0IfP348efLkwcvLi4oVK7J169Yn7n/jxg26dOlCtmzZ8PT0pFChQixfvjxOfSZ2tlFSlSqBh4djYxERERGRBJAiBTRtaqb9AXzwAfz+u0NDkmiwLLh/39FRiIg4DYcmpebNm0ePHj0YMGAAO3fupFSpUtSpU4dLly5Fun9QUBAvvfQSJ06cYOHChRw6dIgpU6aQI0eOWPeZFNiKnKuelIiIiEgy07MnvPMOhISYUVP79zs6InmSYcMgVSrYsMHRkYiIOAWHJqVGjhxJhw4daNu2LcWKFWPixIl4e3szzTaf/jHTpk3j2rVrLF26lKpVq5InTx5q1KhBqVKlYt1nUqAi5yIiIiLJlIuLmb5XowbcugWvvWaKo4tzmjXLJBAXLXJ0JCIiTsFhSamgoCB27NhB7dq1w4JxdaV27dps2rQp0mN++eUXKleuTJcuXciSJQslSpRg6NChBAcHx7rPxO7kSVPr0t0dKld2dDQiIiIikuA8PEySI39+OHECGjc2RdDFuVy7BgcOmPb27Y6NRUTESTgsKXXlyhWCg4PJkiVLuO1ZsmThwoULkR5z7NgxFi5cSHBwMMuXL6dfv36MGDGCIUOGxLpPgMDAQAICAsLdEgvbKKnnnjMjgUVEREQkGcqQAX77zazi988/0KGDqV8kzmPz5rD2zp3w/y/WRUSSM4cXOo+JkJAQMmfOzOTJkylbtix+fn706dOHiRMnxqnfYcOG4evrG3rLlSuXnSKOf7Z6Us8/79g4RERERMTBihSBBQvAzQ1++gm+/NLREcmj/vknrH33rllCW0QkmXNYUipjxoy4ublx8eLFcNsvXrxI1qxZIz0mW7ZsFCpUCDc3t9BtRYsW5cKFCwQFBcWqT4DevXtz8+bN0Nvp06fj8MoSlupJiYiIiEiol16CsWNN+7PPYPFix8YjYTZuDP9YU/hERByXlPLw8KBs2bKsWbMmdFtISAhr1qyhchTFkapWrcqRI0cICQkJ3fbff/+RLVs2PDw8YtUngKenJz4+PuFuicGlS2FfsFSr5thYRERExLHGjx9Pnjx58PLyomLFimzdujXKfR88eMDgwYPJnz8/Xl5elCpVihUrViRgtBKvOnWC99837bfegh07HBuPwIMHYPubfOUVc6+klIiIY6fv9ejRgylTpjBjxgwOHjxIp06duHPnDm3btgWgVatW9O7dO3T/Tp06ce3aNbp3785///3HsmXLGDp0KF26dIl2n0mJbSXZEiUgfXrHxiIiIiKOM2/ePHr06MGAAQPYuXMnpUqVok6dOly6dCnS/fv27cukSZMYO3YsBw4c4L333qNx48bs2rUrgSOXeDNyJNSpA/fuQYMGcPasoyNK3nbvNlP20qUziUKAbdscG5OIiBNwd+TJ/fz8uHz5Mv379+fChQuULl2aFStWhBYqP3XqFK6uYXmzXLlysXLlSj788EOeffZZcuTIQffu3fn000+j3WdSYpu6p3pSIiIiydvIkSPp0KFD6JdwEydOZNmyZUybNo1evXpF2P+nn36iT58+1KtXDzBf/P3xxx+MGDGCmTNnJmjsEk/c3WHePKhSxaz41rChKUbq7e3oyJIn29S9ypWhQgXT9vc3I6hSpHBYWCIijubQpBRA165d6dq1a6TPrV27NsK2ypUrs/nRlSti2GdSYityrnpSIiIiyVdQUBA7duwIN7rc1dWV2rVrs2nTpkiPCQwMxMvLK9y2lClTssE2DFuSBl9f+PVXqFjRTOFr1QrmzwfXRLXWUdJgK3JetSoUKGB+Njdvwv79ULq0Q0MTEXEk/Y+USAUEmC9XQEkpERGR5OzKlSsEBwdHGBWeJUsWLly4EOkxderUYeTIkRw+fJiQkBBWr17N4sWLOX/+fJTnCQwMJCAgINxNEoF8+WDJEvDwgEWL4JNPzOgcSVi2kVJVqoCLC5QrZx6rrpSIJHNKSiVSGzdCSIi5zsiRw9HRiIiISGLy7bffUrBgQYoUKYKHhwddu3albdu24comPG7YsGH4+vqG3nLlypWAEUucVKsGU6aY9ogRZqTOmDFw545j40ouTp2CM2fAzQ3KlzfblJQSEQGUlEq0bPWkNEpKREQkecuYMSNubm5cvHgx3PaLFy+SNWvWSI/JlCkTS5cu5c6dO5w8eZJ///2X1KlTky9fvijP07t3b27evBl6O336tF1fh8SzVq1g0iTIksUkSbp3h9y5YfBguHrVMTEdOQJt2oQN/0+qbKOkypSBVKlMW0kpERFASalEy1ZPSkXORUREkjcPDw/Kli3LmjVrQreFhISwZs0aKleu/MRjvby8yJEjBw8fPmTRokU0bNgwyn09PT3x8fEJd5NEpmNHOHECJk40w+2vXoUBA0xyqkcPSMhEY0AAvPoqzJgB7dqBZSXcuROarZ5UlSph22xJqT17IDAw4WMSEXESSkolQvfvw9atpq2RUiIiItKjRw+mTJnCjBkzOHjwIJ06deLOnTuhq/G1atUqXCH0LVu2sHjxYo4dO8b69et55ZVXCAkJ4ZNPPnHUS5CE4uUF774Lhw7B3LmmyPadOzBqlElUtW0LBw/GbwyWZUZI/fefebxzJyxfHr/ndCTbSKmqVcO25c4NGTKY+l579jgmLhERJ6CkVCK0dSsEBUHWrKYkgIiIiCRvfn5+DB8+nP79+1O6dGn8/f1ZsWJFaPHzU6dOhStifv/+ffr27UuxYsVo3LgxOXLkYMOGDaRNm9ZBr0ASnLs7+PmZhNCKFVCzJjx8CNOnQ7Fi0LgxPGXF61j76quw4uuvvWa2DR6cNEdL3b4Nu3eb9qMjpVTsXEQEAHdHByAx92g9KRcXx8YiIiIizqFr16507do10ufWrl0b7nGNGjU4cOBAAkQlTs/FBerUMbfNm03CaOnSsNsLL8BPP0H27PY53x9/QJ8+pj12LDRsCHnzmm9dV6+Gl1+2z3mcxdatEBwMzzwDOXOGf658eVi5UkkpEUnWNFIqEVI9KRERERGxu0qVzAimAwfMND53d/jzT3PReeJE3Ps/eRKaNTNLSL/zDnToYAqvv/uueX7QoKQ3WiqyelI2GiklIqKkVGLz8GHYtHTVkxIRERERuytaFKZNM8mpvHnh6FFz4XnoUOz7vH8fXn/dFFcvWxbGjw8b8v/xx+DpaS5y//rLPq/BWURWT8rGlpTavx/u3k24mEREnIiSUonM7t1manratFCihKOjEREREZEkq2BBUzeiSBE4c8aMmIptUe6uXWHHDlPce9EiU3DdJnt2M2oKTG2ppCIkBDZtMu3IRkplz26KxAYHh9WdEhFJZpSUSmRsU/eqVgU3N8fGIiIiIiJJXI4c5gK0dGm4dAlq1IAtW2LWx5QpMHUquLrCnDlm5bnHffqpKXz+999hF7yJ3YEDcPMmpEoFzz4b8flHi51v25awsYmIOAklpRIZW5Fz1ZMSERERkQSRKZOZVle5Mty4AbVrw2PF86O0dasZJQUwZAi89FLk++XMaepMAXz+eVwjdg62qXsVK5r6XJFRXSkRSeaUlEpELCv8ynsiIiIiIgkibVpYtcqsxnf7NtStC8uXP/mYy5fhjTcgKAgaNYJevZ68f69eJnnzxx9hCZ3EzFbkPLJ6Ujbly5t7JaVEJJlSUioR+fdfuHIFUqY09SFFRERERBJM6tSwbBnUr28KlzdqBAsXRr7vw4dmpb3Tp6FQIZgxI6yweVRy54bWrU07KYyWsiXWIqsnZWO7qP/3X7h1K/5jEhFxMkpKJSK26fWVKpkp9yIiIiIiCcrLyxQq9/ODBw/M/YwZEffr0wf+/NPUU1qyBHx8otd/796mcOqKFYm7ztLFi3DkiEnEVaoU9X5ZskCuXGZKxK5dCRefiIiTUFIqEdHUPRERERFxuBQpYNYsaNfOrDDXpg2MHx/2/MKF8PXXpv3DD1CsWPT7zp8f3nrLtBPzaCnbqnvFi5upj0+iulIikowpKZWI2EZKqci5iIiIiDiUmxtMngzdu5vHXbvCl1/CwYPQtq3Z9tFH0LRpzPv+7DOzUt+vvybe0UO2elJPmrpnoxX4RCQZU1IqkTh50kzJd3d/8ghgEREREZEE4eoKo0ZB377mce/eJglz+zbUrGmSVLFRqJCpRwWJd7SUrZ7Uk4qc22iklIgkY0pKJRK2UVJly5qp+SIiIiIiDufiYhJHX31lHt+4ATlywLx55tvU2OrTx/S9ZAns3WuXUBPM/fthCaaYjJQ6cgSuX4+/uEREnJCSUomE6kmJiIiIiNP65BOYOtWMkPr5Z8icOW79FSsWNvVvyJA4hxdtY8aYJJtlxb6PnTshKMi8B/nzP33/9OkhX76wY0VEkhElpRIJW1JK9aRERERExCm98w789ZcZ2m8PtmmBCxbAgQP26fNJtm0zNbL694fffot9P4/Wk3Jxid4xmsInIsmUklKJwKVL8O+/ph2daekiIiIiIoleyZLQuLEZtfTFF/F/vkGDwtr9+5uVBWMjJvWkbJSUEpFkSkmpRGDDBnNfsqQZ3SsiIiIikiz062fu586F//6Lv/Ns3QrLlpni7alSgb+/qWcVU5YVs5X3bLQCn4gkU0pKJQK2IueqJyUiIiIiyUqZMlC/vhm1NHRo/J3HNkrq7behRw/THjAg5qOljh6Fy5fBwyNm0xife87cnzxpjhcRSSaUlEoEVORcRERERJIt22ipmTNN0sfetm6F5cvBzc3UserRA9Kmhf37Yf78mPVlGyVVrhx4ekb/OF9fKFTItHfsiNk5RUQSMSWlnFxAgBk9DEpKiYiIiEgyVL481K0LwcEwbJj9+x840Ny//TYUKGASUh99FPbcw4fR7ys29aRsypc396orJSLJiJJSTm7TJjNqOG9eyJHD0dGIiIiIiDiAbbTUjBlmipu9bNkCv/9uRkn16RO2vXt3U8z10CGYMyf6/dmSUjGpJ2WjYucikgwpKeXk4vJli4iIiIhIklC5MtSubUYtPbpKXlw9PkrKJk0a+OQT0x40CB48eHpfN26YKX+gpJSISDQpKeXkbNPSlZQSERERkWTNloz64QdYvDju/W3eDCtWhNWSelzXrpA5s6lj9eOP0evPskxyK3PmmMdTurRZ/e/sWTh/PubHi4gkQkpKObGHD83/baCklIiIiIgkc1WqhI1eatcOTpyIW3+2JFerVpA/f8TnU6WCXr1M+/PPISjoyf3F9dvk1KmhaFHT1mgpEUkmlJRyYnv2wJ07ZjGO4sUdHY2IiIiIiIMNGQKVKpmpcs2bR29aXWQ2bXryKCmb996DbNlMHatp057cZ1zqSdloCp+IJDNKSjkx25ctlSubkbwiIiIiIslaihSm8Livr5lSYCuAHlO2UVKtW0O+fFHvlzIlfPaZaQ8ZAvfvR77fw4emaDrEbYqDVuATkWRGqQ4npnpSIiIiIiKPyZMHpk417a++gpUrY3b8pk3mGHf38CvuRaVDB8iZ09R6mjw58n0eneJgm4IXG4+OlLKs2PcjIpJIKCnlxJSUEhERERGJxOuvQ6dOpv322zErDG5bce9po6RsPD3DpvgNHQp370bcx15THJ591iTLLl2CM2di34+ISCKhpJSTOnXK/D/k5gYVKjg6GhERERERJzNypEniXL4Mb70FwcFPP2bjRli1KvqjpGzatjUjtC5ehO++i7xfiPu3ySlTQokSpr1tW9z6EhFJBJSUclK2L1vKlDELf4iIiIiIyCO8vGDePPD2hj//hC+/fPoxtlFSbdpA3rzRP5eHB/Tvb9pffgm3b4d/3nbxHpci5zYqdi4iyYiSUk7KHot3iIiIiIgkaUWKwPjxpt2/P2zYEPW+//wDq1fHfJSUzdtvQ4ECcOUKjB0btv30aXOz1xQHJaVEJBlRUspJqZ6UiIiIiEg0tG5tpu+FhEDz5nD1auT72Vbcs03Fiyl3dxgwwLS/+QYCAkzb9m1yqVKQOnXM+32cip2LSDKipJQTunULdu82bSWlRERERESewMUFJkyAggVNUdZ33omYzHl0lNRnn8X+XM2bm9FZ16/D6NFmm73qSdmULGmmC16/DseP26dPEREnpaSUE9qyxXzRkzs35Mjh6GhERERERJxcmjSmvpSHB/zyC4wZE/55Wy2p2I6SsnFzC+tr5EiTOLJ33Q0PDzPqCjSFT0SSPCWlnJCm7omIiIiIxFCZMjB8uGl//DHs2GHaGzbAH3/EvpbU45o2NaOZbt6Ezz+HXbvMdntevNum8GkFPhFJ4pSUckJKSomIiIiIxELXrtCoETx4AH5+pu6TbWTTO++YqQhx5eoaVp9q1CgIDoacOSFXrrj3bZOQxc7//BMOHoz/84iIREJJKScTHAybN5u2klIiIiIiIjHg4gJTp8Izz8DRo/Dyy7BmDaRIEbdaUo9r1MiMzLKx94W7LSm1Y4ep6xFfVq6EF1+EWrXg/v34O49IQps5E156CU6dcnQk8hRKSjmZvXtNoXMfHyhRwtHRiIiISGIxfvx48uTJg5eXFxUrVmTr1q1P3H/06NEULlyYlClTkitXLj788EPu60OpJAXp08Ps2ab+05YtZpu9RknZuLjA4MFhj+1VT8qmWDFImdJ8MDh82L592zx8CB9+aNoXL5qaXCJJwYMH8NFHZtpuz56OjkaeQkkpJ2Obulepkvl/VERERORp5s2bR48ePRgwYAA7d+6kVKlS1KlTh0uXLkW6/+zZs+nVqxcDBgzg4MGDTJ06lXnz5vGZPUeSiDhS1aphSSN7j5KyefVVeOEF8PSEevXs27e7e9hIrPiawjdpUvhpe2PHRly1UCQxWrECbP//LVgQlpwWp6SklJOxJaXs/WWLiIiIJF0jR46kQ4cOtG3blmLFijFx4kS8vb2ZNm1apPtv3LiRqlWr0qJFC/LkycPLL79M8+bNnzq6SiRR6dULvv4a5s410/nszcUFli2DM2egQAH79x+fdaWuX4f+/U170CCTWNuxI6yOiEhi9sMP5j5VKnPfs6f9E65nzkDLlmZ6cGIWHOzoCJSUcja2FWVVT0pERESiIygoiB07dlC7du3Qba6urtSuXZtNmzZFekyVKlXYsWNHaBLq2LFjLF++nHpPGO0RGBhIQEBAuJuIU3N1NavwNWkSf+fw8oKMGeOn7/hcgW/wYLh2DYoXN6PImjc328eNs/+5RBLS5cvw66+mvWiRmQa7YQP88ov9zmFZZkrw7NnQsCHs2WO/vhPKyZPQu7dZoOHsWYeGoqSUEzl71vxuuLpCxYqOjkZEREQSgytXrhAcHEyWLFnCbc+SJQsXLlyI9JgWLVowePBgqlWrRooUKcifPz81a9Z84vS9YcOG4evrG3rLZc+VxkQkIltSatcuU//JXg4dCks+jRplpgq+/755vGABRPHvhkiiMHu2+XspVw7q1Amrm/bpp6bWlD3MnAmrV5v2nTvQoIFJhjk7yzJ1tho1gnz54Msv4fx5+Oknh4alpJQTsU3dK1UK0qRxbCwiIiKSdK1du5ahQ4cyYcIEdu7cyeLFi1m2bBmff/55lMf07t2bmzdvht5Onz6dgBGLJEOFCkHq1HD3Lvz7r/36/egj86H9tdfM6mQAzz1n6oc8eGBqTYkkVrape23bmvtPPjGjGQ8dMitzxtXly+ETXQUKmJElr78OQUFx7z8+3LxpasYVLWr+5n/+2azq+eKLsGSJw4vBKynlRGxJKU3dExERkejKmDEjbm5uXLx4Mdz2ixcvkjVr1kiP6devH2+//Tbt27enZMmSNG7cmKFDhzJs2DBColh+3tPTEx8fn3A3EYlHbm4mWQT2qyu1cqWpg+XuDsOHh3/ONlpq4kTn/XAt8iT+/rB7N3h4QLNmZpuvb1j9tAEDzIqWcfHhh3D1qhlJ8vnnZqqgjw+sXw9duzrXYgH790PnzpAjB3TrZhJzadKYOA8cCBs15e7u0DCdIikVkyWMp0+fjouLS7ibl5dXuH3atGkTYZ9XXnklvl9GnCkpJSIiIjHl4eFB2bJlWfNIsdWQkBDWrFlD5cqVIz3m7t27uLqGvwx0+/+yv5YzXVCLJHcVKpj70aPNaIe4ePgQevQw7a5doXDh8M83aQJZs5rpe4sWxe1cIo5gGyXVqBGkTx+2/d13zYimS5ciJmNj4vffYdYsU29nyhSzsmeRImYxBRcXs83RddkePICFC6FWLShRAr77zkwxLFYMxo83NYNso6achMOTUjFdwhjAx8eH8+fPh95OnjwZYZ9XXnkl3D5z5syJz5cRZ7dvm8QuKCklIiIiMdOjRw+mTJnCjBkzOHjwIJ06deLOnTu0/f/0hVatWtG7d+/Q/evXr893333H3LlzOX78OKtXr6Zfv37Ur18/NDklIk6gSxfInNmM/mjUCO7fj31fkyeb0RHp04eNHHmUhwe8955pO/qDtUhMBQWZhBFAmzbhn/PwgGHDTHv4cFNHKaZu34ZOnUy7e3coXz7subp1zUqfYEZS/fFHzPu3h6lTIW9eaNoU1q41oy1ffx3+/BP27TOjppywTpBjx2kRfgljgIkTJ7Js2TKmTZtGr169Ij3GxcUlyuHoNp6enk/dx5ls3WpWY8yVy9xEREREosvPz4/Lly/Tv39/Lly4QOnSpVmxYkVo8fNTp06FGxnVt29fXFxc6Nu3L2fPniVTpkzUr1+fL774wlEvQUQikyePGZ1Rs6b5kNmyJcyfbz5sxsT162GJqMGDIV26yPd791344guzJPjOnWHTB0Wc3W+/mWl12bPDyy9HfP7116FSJdi82Uzjmzw5Zv3362dqR+XObf6GHvfRR7B3L/z4I7z5JmzZAgULxu61xMaPP0L79qadOTN07Gj+nnPmTLgYYsmhI6Vis4QxwO3bt8mdOze5cuWiYcOG7N+/P8I+a9euJXPmzBQuXJhOnTpx9erVeHkN9mKbulelimPjEBERkcSpa9eunDx5ksDAQLZs2ULFR5byXbt2LdOnTw997O7uzoABAzhy5Aj37t3j1KlTjB8/nrRp0yZ84CLyZM89ZwoTe3jA4sVmtENMp9l+/rn5wF6smPmgGpWsWc0oCzBTfEQSC9v/cW+/HXnS1sUlbOre1Klm1GB0bd0KY8aY9sSJZgGCyPqfNMkkvq5fNyvyxXXKbXT9+Se0a2faH34Ip06Zv/lEkJACByelYrOEceHChZk2bRo///wzM2fOJCQkhCpVqnDmzJnQfV555RV+/PFH1qxZw1dffcXff/9N3bp1CQ4OjrTPwMBAAgICwt0SmupJiYiIiIhIpGrVMkvdu7iYER6RTb+Lyn//hSWYRo16elFjW8HzOXMSxzL3IhcuwPLlpv341L1HVa0KjRublec+/TR6fT94YEYghYSYkYpPqlXt5WUSxzlymBUzmzc306Hi04EDph7cw4fg52cSb56e8XtOO3N4TamYqly5Mq1ataJ06dLUqFGDxYsXkylTJiY9snRps2bNaNCgASVLlqRRo0b89ttvbNu2jbVr10ba57Bhw/D19Q295Urg+XPBwWAbGKaklIiIiIiIRPD666ZoMcCQIdEfydSzp/nA+uqrkU9relzFilC2LAQGwvffxz5ekYQya5b5UF2pkik8/iTDhpmRVL/9ZqbEPs0335hpeRkymKTu02TLZkY2pkxppt5GUZLILi5cgHr1zIisqlXNaDHXRJficWxSKjZLGD8uRYoUlClThiNHjkS5T758+ciYMWOU+/Tu3ZubN2+G3k6fPh39F2EHBw5AQACkSgXPPpugpxYRERERkcTi3XfD6tl062ZGMz3J6tVmyXp39+ivOubiEjZa6rvvTEJLxFlZVtiqe/+vU/1EhQuHTWH9+GMzAioq//0X9vc2ahRkyhS9mMqWDYtp+HCYMSN6x8XEnTtQv76pc1WwoEmEeXnZ/zwJwKFJqdgsYfy44OBg9u7dS7Zs2aLc58yZM1y9ejXKfTw9PfHx8Ql3S0i2qXuVKj19NK2IiIiIiCRjfftC166m3bo1rFoV+X4PH5r6MmBW8XvaCJJH+flBxoxw+jT88kvc4hWJTzt2wP79JiHj5xe9Y/r3N3Whtm83CwdEJiTEFAsPDDQjDN96K2Zx+fmZv1Uw/WzeHLPjnyQ42EwN3L7d/J0uX25GciVSDh/bFdMljAcPHsyqVas4duwYO3fu5K233uLkyZO0/3+l+du3b/Pxxx+zefNmTpw4wZo1a2jYsCEFChSgTp06DnmNT6N6UiIiIiIiEi0uLvDtt9Csmal306SJKcT8uClTzIf19OljVoMKzAf8jh1NO64FzwMC4PDhuPUhzuvWLZMYHTTIjMxLaLYRSU2agK9v9I7JkiWsptRnn5nE0+OmTYO//wZvb1Pc3MUl5rENGgSNGkFQkLl/pA52rFkWfPCBGQHp6WmSxgUKxL1fB3J4UsrPz4/hw4fTv39/Spcujb+/f4QljM+fPx+6//Xr1+nQoQNFixalXr16BAQEsHHjRooVKwaAm5sbe/bsoUGDBhQqVIh27dpRtmxZ1q9fj6eTFvxSUkpERERERKLN1dVMCXr5ZTONp149U1jZ5sYNs4Q9mA/G6dPH/BzvvWdq76xda2rqxMa+fWa6VJEipr6OJH7XrplESM+eUKECpEsHderAwIHmPiFXbbx/P2wK65MKnEfmww9N/afjx2HChPDPnT9vXh+YVezy5o1dfK6u8NNPULIkXLwIDRvC3bux68vm229h3DjTnjkTojnDzJm5WFZM1xNN+gICAvD19eXmzZvxPpXv/HnInt38vl6/Dgk8c1BERERiKCGvE5yZ3gcRJ3D7NrzwAmzbBrlywcaNZhn4jz6CkSOhWDHYvTv2NULeeAMWLTKjph5ZWCpatm0zK5Vdu2YeZ8sWVjBaEo/z52H9eli3ztwiS1DmyQPPPGOeB+jRwxQIj++i2/Pnm2lyuXKZ5JKbW8yO//576NDBJNaOHjX3AE2bwsKFpjbU5s1xr7Fz4gSULw9XrpiFBD77zCw8ENN4lywxCx5Ylnl/bYkzJxXd6wSHj5RK7myjpEqWVEJKRERERERiIHVqWLbMjEY6fdqMVNmyBcaMMc+PHBm3D9S2guczZ5pv0KPr779NsuzaNfMhvEgRk9zo0iX2sUjCuXwZOneGQoXMCAo/Pxg/PiwhVbSoKRY+c6YptH38uBlRN2yYeX7kSHPM/fvxG+f06ea+VauYJ3jAjK4qXtz8btti//lnk5ByczNJK3sUfc6TxyR3vbzM32fDhua9/fZbM701OrZsgRYtTEKqUyeTeE4ilJRyMFtSqkoVx8YhIiIiIiKJUKZMsHIl5MhhlvWuWtUUOa9XzySp4uL5582353fvhtXueZrly80Iqdu3oVYtU2fop5/Mh/x582Du3LjFJPHr7FmoUcOsvHj4sKmlVKYMdO9uEisXL5rfs4kToWVLM0IKzH69esGsWZAihUns1K4NV6/GX5wrV5p2TKfu2bi7w1dfmfaYMSbp1rmzedyzJ5QuHdcowzz/vFnN79NPzYisY8dMbaicOc1UwmPHoj722DGz0t79+2aE1Zgxsatx5aSUlHIw1ZMSEREREZE4yZ3bfEBPl86szOXmBiNGxL1fF5ew0VLjx5u+n2TBAjMK5P598yF6+XJIkwbKlQurcdW5s0koiPM5ftwkTw4eNMmSX34xo9127oTRo00x8cyZn9xHixam8Lmvr/mwW7XqkxMusTVzplkhr1q1uBX6rlfPJE8DA01f585B/vwwYID9YrXJlQu+/NKMavzuOzOC8NYt894WKGCKoa9da0ZD2Vy7ZmK8fNkkB+fOtc/oLSeipJQD3b0Lu3aZtpJSIiIiIiISa8WLm6l8BQrA4MHmA689tGgBadOaxMKTipVPm2ZWBHz40CxXb5uuZPPZZyY5df06tGsX/oO3ON6//0L16ubnnD+/qSNVv7752cdUzZomIZUrFxw6ZIpxb9tmv1gtK2zkXtu2cevLxcXUZ4KwqXSTJ0PKlHHr90lSpTILCezfb/6m6tQxr+nnn02CrEwZMzUxIAAaNzbvYa5c8NtvZspuEqOklANt22b+zc6e3Xy5ISIiIiIiEmuVK5spV599Zr8+U6UySSSIemW1b781+4SEmMLRP/1kpnA9KkUKs93Ly4zqmjjRfjE6k+vXzSibL78070disHu3GSF19qwpjr9unamDFBfFi5si4aVLw6VLJlH16692CBZTX+nQIfD2NkXJ46psWTMVEUyS64UX4t5ndLi6mqmuK1aYKZHvvWeSYbt3mzgyZTI/Cx8fk3DOnj1h4kpgSko50KNT95LQlFAREREREUlKOnc2H1hWrTLJABvLgs8/N7VxwBRfnjQp6qLTRYqE1fDp2dMk0JKKhw9hwgQoWNCMVOvdG7p2jZ8RYZZlVnKzh82bTcLo8mV47jlTpN5eyY/s2U1SpU4dM02oUSMzbS2ubKOk3njDTA+1h8mTTR0sRyVLixY1782ZMyahmTMnBAWZqXqLFpnabkmUklIOpHpSIiIiIiLi9PLlg9deM+3x4829ZcEnn0D//ubx4MFmGtTTvm3v2tWMRLl7F1q3NsmcxG7FCihVyqwuePWqmf7m4mKSDD3+196dB1ddXn8c/9yQxRCSEAiQRGSPQcCkI2oatypJgWAtW1sYUxulSonBgpbWXcCpA0MVFUvjVomtlFgcNlFUREkrgrKFpUQKNIIdCBEsEAIBhzy/P55fLl4JJiQ393uX92smQ3LXc+4BPRye5/ne593B1NGj0g9/aFfRjBhx9jyY5li92h5GfuSIvfLWBx9IiYleCvT/xcbaFVL1K+nuvtseiN7cVWQnT549LL+5B5w3pG1bafRoKTLSe6/ZHB062MPQ//Mfe6bXP/9paxTEGEo5pK5O+vhj+z1DKQAAAAB+beJE+2txsR1iTJggPfmkve3pp+1B5k3Z/hEWZle6xMVJa9eePc/HF4yxf9lftEjavr3lw6LycnsIdW6u3X7VsaMd2n32mfTyy/YxzzxjV015YzB14IC9Mt6qVfbnpUvt6qaRI6Wysgt7rbfftnHX1EjZ2WcPJ28NERHSSy/ZwaVkV8v9/Of2cPELtXixPWupRw/7WQSriAh7ptf3v+90JK2OoZRDysvtf8vbtrVDdQAAAADwWzk5UlqavVrYVVfZ7U4ulx2+1G/fa6pu3c6eTzV16oUPVJrq1Cm7Pe2pp+yV45KT7Sqm0aPtdqiePe3qphUr7BUDm+rwYXtVwssvt8+NiLAronbtsiuBwsOlcePsdj7JDmGmT29ZLrt22dVMW7bYK+AtWmTPQQoLk5YssYdjN3U49cYbdpVVba304x/bA7RjYloWX2NcLju4LC62n8+CBXZ1xqJFjV/V8ZuKi+2v+fk2dwQ8quiQ+q17mZnnngEIAAAAAH4lLOzsaqndu88OFuoPQb9Qt91mhyhff22/b86qmW/78ku75en+++2V5OLj7eHvU6bYFTYHD9q/fGVk2APX9+61g6Nhw+wqp+HD7Yqe/fsbfv3Tp+3Kpz59pD/+0Q5Thg+3V1F76ikpIcHz8QUFdhWZZIdSM2Y0L68NG+wA5/PP7VDt44/tZ/faa/a98/Ls0Kd+ODVq1PmHU6++Ko0ZYz/3sWPtgOqbV0lsbfn5dpAXFydt3GgHhL1728/vyJHvfu6+fdL77599HQQFhlIOqR9KXXONs3EAAAAAQJPk59szh6Ki7ABkzJjmv5bLZQ9F79zZbqWrP5vqQtTV2SHFuHF2FVfnznZINGuW9NFHdtCVmGhXA82cac/nOXrUDmwOH7ZnHf3qV9LFF9szrpYtk8aPtz8PHGhXca1fb9/nzTelAQOke++1w5P0dLuNbskSe7j5+UyebN9bsldFnD37wnJ87z3Pg8jXrLFDnHp9+9rh1I4d0q232s918eKzw6ktW84+9k9/sucw1dVJd95pn+fEComcHLt16OGH7TBw7147OOza1Q4+//3vhp/317/abZA33mhXuSEouIxpjcsBBLZjx44pPj5eR48eVVxcXKu8R58+0p49Z7fyAgCAwOCLPiEQ8DkAIWr/frtC6JJLvPN6S5farWQul71S23XXNf6cw4ftip/nnz/3Cn79+tl/+b/mGru6KDW18bOujLHDm+XLpbfekj75xPMMqLg4e46RZAdfv/+9HYSd7yqDDXn8cTvkkuwqq8LCxp/zt7+dPQw+O9sOmxq72lx5ub0iYknJ2RxGjbKfQ/2VDydNsiu4/OES8CdPSvPnS88+a4eT9YYNswO9nBwbpzHSpZfaVXqvvir94heOhYymaWqfwFCqAa3dZB08KCUl2T9bX30ltW/v9bcAAACthGGMxecAwGvGjbOHn/fsaYdDDQ1ejLHDoqIi6fXXz273i421h2bffLPdqtehQ8vjqaqyW8yWL5fefdeeoxUZaVdJPfSQHVJdKGPsyqD6LXwvvWRXK53P00/bc6oku82uuNiuUGuqhoZTkvTII3ZA5g8DqW8yxl7979ln7edeH3O/fnaI1qOHNGSI1K6dVFnZ+mdgocUYSrVAazdZixbZrbMDBkjbtnn95QEAQCtiGGPxOQDwmmPH7Ha4vXvt9rkXXjh73/HjdsVQUZHnOUnf+549s+nWW+2gorWcPm3PPurWzW7rawlj7Da12bPtUKi4+NwVP8ZIDzxgtyBKdiAze3bzD/XescMOp958U5o2zb6/v9u92x6E/8ortv7fdMcd9nb4vab2CeE+jAn/7+OP7a/XXutsHAAAAADguLg4O6C56SZ7Vb/hw+0Q6Pnnpb/8xa5UkuxKoTFj7DAqM9M3q30iI+0KLG9wuaQnn7SrvObOtQOW+pwke/j4nXfanCV7FtXvfteyPPv1swfSG+N/q6POp08fu2Lq8cftAOq556SKCnvfuHHOxgavYyjlgPpDzhlKAQAAAIDs4dX33mu3rY0a5Xk1vtRUacIEe0i3N7bnOcnlkubMsfm9/LK9cl5kpDR4sPTTn9ptg23a2Ptuv9277xto4uPt74lf/9p+LmfONO3MMQQUhlI+dvKkXf0pMZQCAAAAALcnnpDeeceeh9SmjV0xVVAgDRrU/O1r/igszG5RPHXKXlFuzBh79cDt26XoaGnhQntGFqw2baQf/cjpKNBKGEr52IYNdlVmUhJXsQQAAAAAt+hoaeVKe4nyYcNafoaTPwsLs1vTTp+2B7dv325XgS1f7r3tgkAAYCjlY4cOScnJ9gqlgbiCEgAAAABazcUXS3fd5XQUvhEebldKxcfbqw7OmydddpnTUQE+xVDKx0aOlEaMkE6ccDoSAAAAAICjIiI8rzYIhJgg2pgbOFwuKSbG6SgAAAAAAACcw1AKAAAAAAAAPsdQCgAAAAAAAD7HUAoAAAAAAAA+x1AKAAAAAAAAPsdQCgAAAAAAAD7HUAoAAAAAAAA+x1AKAAAAAAAAPsdQCgAAAAAAAD7HUAoAAAAAAAA+x1AKAAAAAAAAPhfudAD+yBgjSTp27JjDkQAAAH9T3x/U9wuhin4JAACcT1P7JYZSDaiurpYkXXLJJQ5HAgAA/FV1dbXi4+OdDsMx9EsAAKAxjfVLLhPq/8zXgLq6Ou3fv1+xsbFyuVyNPv7YsWO65JJL9MUXXyguLs4HETor1PKVyJmcg1eo5Rxq+Urk3Bo5G2NUXV2tlJQUhYWF7kkI9EuNC7WcQy1fiZzJOXiFWs6hlq/kP/0SK6UaEBYWpq5du17w8+Li4kLmN7AUevlK5BwqyDn4hVq+Ejl7WyivkKpHv9R0oZZzqOUrkXOoIOfgF2r5Ss73S6H7z3sAAAAAAABwDEMpAAAAAAAA+BxDKS+IiorS1KlTFRUV5XQoPhFq+UrkHCrIOfiFWr4SOcN/hGJdQi3nUMtXIudQQc7BL9TylfwnZw46BwAAAAAAgM+xUgoAAAAAAAA+x1AKAAAAAAAAPsdQCgAAAAAAAD7HUKqF5s6dqx49euiiiy5SZmamPv30U6dDajXTpk2Ty+Xy+Orbt6/TYXnVP/7xD91yyy1KSUmRy+XSkiVLPO43xuixxx5TcnKyoqOjlZOTo127djkTrJc0lvPtt99+Tt2HDh3qTLBeMGPGDF111VWKjY1V586dNWLECO3cudPjMbW1tSosLFTHjh3Vrl07jR49WgcPHnQo4pZrSs433njjOXWeMGGCQxG3XFFRkdLT0xUXF6e4uDhlZWVpxYoV7vuDrcZS4zkHW42/bebMmXK5XJo8ebL7tmCsc6CiX6Jfol8KLPRL9EtS8NVYol/yx36JoVQLvP7667rvvvs0depUbdq0SRkZGRoyZIiqqqqcDq3V9O/fXwcOHHB/ffTRR06H5FU1NTXKyMjQ3LlzG7x/1qxZmjNnjp5//nl98skniomJ0ZAhQ1RbW+vjSL2nsZwlaejQoR51X7BggQ8j9K7S0lIVFhZq3bp1Wrlypb7++msNHjxYNTU17sfce++9evPNN7Vw4UKVlpZq//79GjVqlINRt0xTcpaku+66y6POs2bNcijiluvatatmzpypjRs3asOGDRo0aJCGDx+uf/3rX5KCr8ZS4zlLwVXjb1q/fr1eeOEFpaene9wejHUORPRL9Ev0S4GHfol+SQq+Gkv0S37ZLxk029VXX20KCwvdP585c8akpKSYGTNmOBhV65k6darJyMhwOgyfkWQWL17s/rmurs4kJSWZP/zhD+7bjhw5YqKiosyCBQsciND7vp2zMcbk5+eb4cOHOxKPL1RVVRlJprS01BhjaxoREWEWLlzofkx5ebmRZNauXetUmF717ZyNMeYHP/iBmTRpknNB+UBCQoJ5+eWXQ6LG9epzNiZ4a1xdXW1SU1PNypUrPXIMpTr7O/ql4Ea/ZNEvBd9/Y+mXgr/G9eiXnK0zK6Wa6fTp09q4caNycnLct4WFhSknJ0dr1651MLLWtWvXLqWkpKhXr17Ky8vTvn37nA7JZyoqKlRZWelR8/j4eGVmZgZ1zSVp9erV6ty5s9LS0lRQUKDDhw87HZLXHD16VJLUoUMHSdLGjRv19ddfe9S5b9++6tatW9DU+ds515s/f74SExM1YMAAPfjggzpx4oQT4XndmTNnVFJSopqaGmVlZYVEjb+dc71grHFhYaFuvvlmj3pKofFnORDQL9EvSfRLwYB+6axg/H+pRL9Ev+RcncN98i5B6NChQzpz5oy6dOnicXuXLl302WefORRV68rMzFRxcbHS0tJ04MABTZ8+Xddff722b9+u2NhYp8NrdZWVlZLUYM3r7wtGQ4cO1ahRo9SzZ0/t2bNHDz30kHJzc7V27Vq1adPG6fBapK6uTpMnT9a1116rAQMGSLJ1joyMVPv27T0eGyx1bihnSbr11lvVvXt3paSkaOvWrbr//vu1c+dOLVq0yMFoW2bbtm3KyspSbW2t2rVrp8WLF6tfv34qKysL2hqfL2cpOGtcUlKiTZs2af369efcF+x/lgMF/RL9Ur1g/7NHv2QFS53pl+iXgqnG/t4vMZRCk+Xm5rq/T09PV2Zmprp3766///3v+uUvf+lgZGhNY8eOdX9/+eWXKz09Xb1799bq1auVnZ3tYGQtV1hYqO3btwfdWR/f5Xw5jx8/3v395ZdfruTkZGVnZ2vPnj3q3bu3r8P0irS0NJWVleno0aN64403lJ+fr9LSUqfDalXny7lfv35BV+MvvvhCkyZN0sqVK3XRRRc5HQ7gRr8UmuiXggv9Ev2SFBw1DoR+ie17zZSYmKg2bdqccyr9wYMHlZSU5FBUvtW+fXtdeuml2r17t9Oh+ER9XUO55pLUq1cvJSYmBnzdJ06cqOXLl+vDDz9U165d3bcnJSXp9OnTOnLkiMfjg6HO58u5IZmZmZIU0HWOjIxUnz59NHDgQM2YMUMZGRl69tlng7rG58u5IYFe440bN6qqqkpXXHGFwsPDFR4ertLSUs2ZM0fh4eHq0qVL0NY5kNAv0S/VC6WaS/RLgYx+iX7pmwK9xoHQLzGUaqbIyEgNHDhQq1atct9WV1enVatWeexHDWbHjx/Xnj17lJyc7HQoPtGzZ08lJSV51PzYsWP65JNPQqbmkvTf//5Xhw8fDti6G2M0ceJELV68WB988IF69uzpcf/AgQMVERHhUeedO3dq3759AVvnxnJuSFlZmSQFbJ0bUldXp1OnTgVljc+nPueGBHqNs7OztW3bNpWVlbm/rrzySuXl5bm/D5U6+zP6JfoliX4pENEv0S8FY43Ph37J4Tr75Dj1IFVSUmKioqJMcXGx2bFjhxk/frxp3769qaysdDq0VvGb3/zGrF692lRUVJg1a9aYnJwck5iYaKqqqpwOzWuqq6vN5s2bzebNm40kM3v2bLN582azd+9eY4wxM2fONO3btzdLly41W7duNcOHDzc9e/Y0J0+edDjy5vuunKurq82UKVPM2rVrTUVFhXn//ffNFVdcYVJTU01tba3ToTdLQUGBiY+PN6tXrzYHDhxwf504ccL9mAkTJphu3bqZDz74wGzYsMFkZWWZrKwsB6NumcZy3r17t3n88cfNhg0bTEVFhVm6dKnp1auXueGGGxyOvPkeeOABU1paaioqKszWrVvNAw88YFwul3nvvfeMMcFXY2O+O+dgrHFDvn3FnGCscyCiX6Jfol8KPPRL9EvGBF+NjaFfMsb/+iWGUi303HPPmW7dupnIyEhz9dVXm3Xr1jkdUqsZM2aMSU5ONpGRkebiiy82Y8aMMbt373Y6LK/68MMPjaRzvvLz840x9jLHjz76qOnSpYuJiooy2dnZZufOnc4G3ULflfOJEyfM4MGDTadOnUxERITp3r27ueuuuwL6LxIN5SrJzJs3z/2YkydPmrvvvtskJCSYtm3bmpEjR5oDBw44F3QLNZbzvn37zA033GA6dOhgoqKiTJ8+fcxvf/tbc/ToUWcDb4Fx48aZ7t27m8jISNOpUyeTnZ3tbrCMCb4aG/PdOQdjjRvy7SYrGOscqOiX6JfolwIL/RL9kjHBV2Nj6JeM8b9+yWWMMd5ffwUAAAAAAACcH2dKAQAAAAAAwOcYSgEAAAAAAMDnGEoBAAAAAADA5xhKAQAAAAAAwOcYSgEAAAAAAMDnGEoBAAAAAADA5xhKAQAAAAAAwOcYSgEAAAAAAMDnGEoBgJe4XC4tWbLE6TAAAAD8Gj0TgHoMpQAEhdtvv10ul+ucr6FDhzodGgAAgN+gZwLgT8KdDgAAvGXo0KGaN2+ex21RUVEORQMAAOCf6JkA+AtWSgEIGlFRUUpKSvL4SkhIkGSXiRcVFSk3N1fR0dHq1auX3njjDY/nb9u2TYMGDVJ0dLQ6duyo8ePH6/jx4x6PeeWVV9S/f39FRUUpOTlZEydO9Lj/0KFDGjlypNq2bavU1FQtW7bMfd///vc/5eXlqVOnToqOjlZqauo5DSEAAEBro2cC4C8YSgEIGY8++qhGjx6tLVu2KC8vT2PHjlV5ebkkqaamRkOGDFFCQoLWr1+vhQsX6v333/dooIqKilRYWKjx48dr27ZtWrZsmfr06ePxHtOnT9fPfvYzbd26VcOGDVNeXp6++uor9/vv2LFDK1asUHl5uYqKipSYmOi7DwAAAKAJ6JkA+IwBgCCQn59v2rRpY2JiYjy+nnjiCWOMMZLMhAkTPJ6TmZlpCgoKjDHGvPjiiyYhIcEcP37cff9bb71lwsLCTGVlpTHGmJSUFPPwww+fNwZJ5pFHHnH/fPz4cSPJrFixwhhjzC233GLuuOMO7yQMAADQDPRMAPwJZ0oBCBo33XSTioqKPG7r0KGD+/usrCyP+7KyslRWViZJKi8vV0ZGhmJiYtz3X3vttaqrq9POnTvlcrm0f/9+ZWdnf2cM6enp7u9jYmIUFxenqqoqSVJBQYFGjx6tTZs2afDgwRoxYoSuueaaZuUKAADQXPRMAPwFQykAQSMmJuacpeHeEh0d3aTHRUREePzscrlUV1cnScrNzdXevXv19ttva+XKlcrOzlZhYaGefPJJr8cLAABwPvRMAPwFZ0oBCBnr1q075+fLLrtMknTZZZdpy5Ytqqmpcd+/Zs0ahYWFKS0tTbGxserRo4dWrVrVohg6deqk/Px8vfbaa3rmmWf04osvtuj1AAAAvI2eCYCvsFIKQNA4deqUKisrPW4LDw93H4y5cOFCXXnllbruuus0f/58ffrpp/rzn/8sScrLy9PUqVOVn5+vadOm6csvv9Q999yj2267TV26dJEkTZs2TRMmTFDnzp2Vm5ur6upqrVmzRvfcc0+T4nvsscc0cOBA9e/fX6dOndLy5cvdDR4AAICv0DMB8BcMpQAEjXfeeUfJycket6Wlpemzzz6TZK/yUlJSorvvvlvJyclasGCB+vXrJ0lq27at3n33XU2aNElXXXWV2rZtq9GjR2v27Nnu18rPz1dtba2efvppTZkyRYmJifrJT37S5PgiIyP14IMP6vPPP1d0dLSuv/56lZSUeCFzAACApqNnAuAvXMYY43QQANDaXC6XFi9erBEjRjgdCgAAgN+iZwLgS5wpBQAAAAAAAJ9jKAUAAAAAAACfY/seAAAAAAAAfI6VUgAAAAAAAPA5hlIAAAAAAADwOYZSAAAAAAAA8DmGUgAAAAAAAPA5hlIAAAAAAADwOYZSAAAAAAAA8DmGUgAAAAAAAPA5hlIAAAAAAADwOYZSAAAAAAAA8Ln/Ay7KF+SHAXYNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final validation accuracy: 0.7504\n",
            "Final validation loss: 0.7996\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "회고\n",
        "적절한 hp를, 적절하게 조정하고, 과적합을 조심하자?\n",
        "\n",
        "정해진 시간과 목표가 무엇인지 잊지말자."
      ],
      "metadata": {
        "id": "DugydG_YyoEr"
      }
    }
  ]
}